            from src.infrastructure.monitor.remote_resource_collector import RemoteResourceCollector
        import io
from datetime import datetime
from pathlib import Path
from src.application.monitor.resource_monitor_service import ResourceMonitorService
from src.application.services.device_query_service import DeviceQueryService
import argparse
import csv
import glob
import json
import os
import re
import shutil
import subprocess
import sys
import threading
import time

#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆJMETERæ‰¹é‡æ³¨å†Œè„šæœ¬
- å®Œå…¨æ›¿ä»£å›¾å½¢ç•Œé¢æ“ä½œ
- æ”¯æŒä¸åŒçº¿ç¨‹æ•°çš„æ‰¹é‡æ³¨å†Œ
- æ”¯æŒæ‰¹é‡æ³¨å†Œå’Œæ‰¹é‡ç™»å½•ä¸¤ç§æµ‹è¯•åœºæ™¯
- é›†æˆCPUç›‘æ§åŠŸèƒ½
- è‡ªåŠ¨éªŒè¯æ³¨å†Œæ•°é‡
- ç”Ÿæˆç»¼åˆæŠ¥å‘Š
"""

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, ".."))
sys.path.insert(0, project_root)


# è®¾ç½®æ ‡å‡†è¾“å‡ºä¸ºUTF-8ç¼–ç 
if sys.stdout.encoding is None or sys.stdout.encoding.lower() != 'utf-8':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except Exception:
        pass

# å›ºå®šæ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼ˆåªè¯»ï¼Œä¸¥æ ¼å¼•ç”¨å®é™…ä½ç½®ï¼‰
JMX_TEMPLATE_PATH = os.path.join('src', 'tools', 'jmeter', 'bin', 'register_test_python_format.jmx')
CSV_TEMPLATE_PATH = os.path.join('src', 'tools', 'jmeter', 'bin', 'new_devices_100000.csv')
RESULTS_DIR = os.path.join('src', 'tools', 'jmeter', 'results')

class EnhancedJMeterBatchRegister:
    """å¢å¼ºç‰ˆJMETERæ‰¹é‡æ³¨å†Œç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ‰¹é‡æ³¨å†Œæµ‹è¯•ç±»"""
        # ä¿®å¤ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„
        self.jmeter_bin = os.path.abspath(os.path.join('src', 'tools', 'jmeter', 'bin', 'jmeter.bat'))
        self.results_dir = RESULTS_DIR
        os.makedirs(self.results_dir, exist_ok=True)
        
        # åŠ è½½æœåŠ¡å™¨é…ç½®
        self.server_config = {
            'host': '192.168.24.45',
            'username': 'test',
            'password': '1'
        }
        
        # åˆå§‹åŒ–ç›‘æ§æœåŠ¡
        try:
            self.cpu_monitor = RemoteResourceCollector(
                host=self.server_config['host'],
                username=self.server_config['username'],
                password=self.server_config['password']
            )
            # æµ‹è¯•SSHè¿æ¥
            test_result = self.cpu_monitor.get_cpu_usage()
            if test_result is None:
                print("âš ï¸ SSHè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œç¡¬ä»¶ç›‘æ§å°†è¢«ç¦ç”¨")
                self.cpu_monitor = None
            else:
                print("âœ… SSHè¿æ¥æµ‹è¯•æˆåŠŸï¼Œç¡¬ä»¶ç›‘æ§å·²å¯ç”¨")
        except Exception as e:
            print(f"âš ï¸ åˆå§‹åŒ–ç¡¬ä»¶ç›‘æ§å¤±è´¥: {e}ï¼Œç¡¬ä»¶ç›‘æ§å°†è¢«ç¦ç”¨")
            self.cpu_monitor = None
        
        # åˆå§‹åŒ–ç›‘æ§æ•°æ®ç»“æ„ï¼ˆç»Ÿä¸€ä½¿ç”¨monitoring_dataï¼‰
        self.monitoring_data = {
            'cpu': [],
            'memory': [],
            'disk': [],
            'process': []
        }
        
        # æ•°æ®åº“é…ç½®
        self.db_config = {
            'host': '192.168.24.45',
            'port': 3307,
            'user': 'root',
            'password': 'At6mj*1ygb2',
            'database': 'yangguan'
        }
        
        # å¢é‡æµ‹è¯•ç›¸å…³
        self.last_device_count = 0
        self.current_device_count = 0
        # ä¿®å¤ï¼šåˆå§‹åŒ–cpu_monitoringå±æ€§
        self.cpu_monitoring = False

    def check_prerequisites(self):
        """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
        # æ£€æŸ¥JMeterå¯æ‰§è¡Œæ–‡ä»¶
        if not os.path.exists(self.jmeter_bin):
            print(f"âŒ JMeterå¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨: {self.jmeter_bin}")
            return False
            
        # æ£€æŸ¥JMXæ¨¡æ¿æ–‡ä»¶
        if not os.path.exists(JMX_TEMPLATE_PATH):
            print(f"âŒ JMXæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {JMX_TEMPLATE_PATH}")
            return False
            
        # æ£€æŸ¥ç»“æœç›®å½•
        if not os.path.exists(self.results_dir):
            try:
                os.makedirs(self.results_dir)
                print(f"âœ… åˆ›å»ºç»“æœç›®å½•: {self.results_dir}")
            except Exception as e:
                print(f"âŒ åˆ›å»ºç»“æœç›®å½•å¤±è´¥: {e}")
                return False
                
        return True
    
    def get_device_count_before(self):
        """è·å–æ³¨å†Œå‰çš„è®¾å¤‡æ•°é‡"""
        print("ğŸ“Š è·å–æ³¨å†Œå‰çš„è®¾å¤‡æ•°é‡...")
        try:
            service = DeviceQueryService(self.db_config)
            count = service.get_device_count('biz_device')
            service.close()
            print(f"ğŸ“ˆ æ³¨å†Œå‰è®¾å¤‡æ€»æ•°: {count}")
            return count
        except Exception as e:
            print(f"âŒ è·å–è®¾å¤‡æ•°é‡å¤±è´¥: {e}")
            return 0
    
    def modify_jmx_threads(self, thread_count, loops=1):
        """ä»¥å›ºå®šæ¨¡æ¿ç”Ÿæˆæ–°JMXï¼Œçº¿ç¨‹æ•°/å¾ªç¯æ•°å¯å˜ï¼Œè¾“å‡ºåˆ°resultsç›®å½•ï¼Œå¹¶æ ¡éªŒå¾ªç¯æ¬¡æ•°å‚æ•°æ˜¯å¦ç”Ÿæ•ˆ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        new_jmx = os.path.join(self.results_dir, f'register_test_{thread_count}threads_{loops}loops_{timestamp}.jmx')
        try:
            shutil.copy2(JMX_TEMPLATE_PATH, new_jmx)
            with open(new_jmx, 'r', encoding='utf-8') as f:
                content = f.read()
            content = re.sub(r'<stringProp name="ThreadGroup.num_threads">\d+</stringProp>',
                            f'<stringProp name="ThreadGroup.num_threads">{thread_count}</stringProp>', content)
            content = re.sub(r'<stringProp name="LoopController.loops">\d+</stringProp>',
                            f'<stringProp name="LoopController.loops">{loops}</stringProp>', content)
            with open(new_jmx, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"ğŸ”§ ä¿®æ”¹åçš„JMXæ–‡ä»¶å·²ä¿å­˜: {new_jmx}")
            # æ ¡éªŒå¾ªç¯æ¬¡æ•°å‚æ•°
            with open(new_jmx, 'r', encoding='utf-8') as f:
                check_content = f.read()
            match = re.search(r'<stringProp name="LoopController.loops">(\d+)</stringProp>', check_content)
            if match:
                actual_loops = int(match.group(1))
                print(f"âœ… JMXå¾ªç¯æ¬¡æ•°å‚æ•°å·²è®¾ç½®ä¸º: {actual_loops}")
                if actual_loops != loops:
                    print(f"âŒ [å¾ªç¯æ¬¡æ•°æ ¡éªŒå¤±è´¥] æœŸæœ›: {loops}ï¼Œå®é™…: {actual_loops}ï¼Œè¯·æ£€æŸ¥æ¨¡æ¿æ›¿æ¢é€»è¾‘ï¼")
                    raise ValueError("JMXå¾ªç¯æ¬¡æ•°å‚æ•°æœªæ­£ç¡®æ›¿æ¢")
            else:
                print("âŒ [å¾ªç¯æ¬¡æ•°æ ¡éªŒå¤±è´¥] æœªæ‰¾åˆ°LoopController.loopså­—æ®µï¼")
                raise ValueError("JMXå¾ªç¯æ¬¡æ•°å‚æ•°æœªæ‰¾åˆ°")
            return new_jmx
        except Exception as e:
            print(f"âŒ ä¿®æ”¹JMXæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def prepare_csv(self):
        """å§‹ç»ˆä»¥å›ºå®šCSVæ¨¡æ¿ç”Ÿæˆæ–°CSVï¼Œè¾“å‡ºåˆ°resultsç›®å½•ï¼Œå‘½åå¸¦æ—¶é—´æˆ³"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        new_csv = os.path.join(self.results_dir, f'new_devices_for_test_{timestamp}.csv')
        shutil.copy2(CSV_TEMPLATE_PATH, new_csv)
        print(f"âœ… ç”Ÿæˆæµ‹è¯•ç”¨CSV: {new_csv}")
        return new_csv
    
    def start_cpu_monitoring(self, duration, interval=2):
        """å¯åŠ¨CPUç›‘æ§"""
        if not self.cpu_monitor:
            print("âš ï¸ ç¡¬ä»¶ç›‘æ§æœªå¯ç”¨ï¼Œè·³è¿‡ç›‘æ§")
            return
            
        self.monitoring_start_time = time.time()
        self.monitoring_duration = duration
        self.monitoring_interval = interval
        # ä¿®å¤ï¼šå¯åŠ¨æ—¶è®¾ç½®cpu_monitoringä¸ºTrue
        self.cpu_monitoring = True

        def monitor_resources():
            while time.time() - self.monitoring_start_time < self.monitoring_duration and self.cpu_monitoring:
                try:
                    # é‡‡é›†CPUä½¿ç”¨ç‡
                    cpu_usage = self.cpu_monitor.get_cpu_usage()
                    if cpu_usage is not None:
                        self.monitoring_data['cpu'].append((time.time(), cpu_usage))

                    # é‡‡é›†å†…å­˜ä½¿ç”¨ç‡
                    memory_info = self.cpu_monitor.get_memory_usage()
                    if memory_info is not None:
                        self.monitoring_data['memory'].append((time.time(), memory_info))

                    # é‡‡é›†ç£ç›˜ä½¿ç”¨ç‡
                    disk_info = self.cpu_monitor.get_disk_usage()
                    if disk_info is not None:
                        self.monitoring_data['disk'].append((time.time(), disk_info))

                    # é‡‡é›†è¿›ç¨‹ä¿¡æ¯
                    process_info = self.cpu_monitor.get_process_info()
                    if process_info is not None:
                        self.monitoring_data['process'].append((time.time(), process_info))

                    time.sleep(self.monitoring_interval)
                except Exception as e:
                    print(f"âš ï¸ ç›‘æ§æ•°æ®é‡‡é›†å¼‚å¸¸: {e}")
                    time.sleep(1)

        self.monitoring_thread = threading.Thread(target=monitor_resources)
        self.monitoring_thread.daemon = True
        self.monitoring_thread.start()
        print("ğŸ”„ ç¡¬ä»¶ç›‘æ§å·²å¯åŠ¨")
    
    def stop_cpu_monitoring(self):
        """åœæ­¢ç³»ç»Ÿèµ„æºç›‘æ§å¹¶å…³é—­è¿æ¥"""
        if self.cpu_monitoring:
            self.cpu_monitoring = False
            if hasattr(self, 'monitoring_thread'):
                self.monitoring_thread.join(timeout=5)
            print("ğŸ›‘ ç³»ç»Ÿèµ„æºç›‘æ§å·²åœæ­¢")
        # ç¡®ä¿å…³é—­SSHè¿æ¥
        if self.cpu_monitor:
            # ä¿®å¤ï¼šRemoteResourceCollectoræ²¡æœ‰closeæ–¹æ³•ï¼Œéœ€åˆ¤æ–­åå†è°ƒç”¨
            if hasattr(self.cpu_monitor, 'close') and callable(self.cpu_monitor.close):
                self.cpu_monitor.close()
            # å¦åˆ™ä»…ç½®ä¸ºNone
            self.cpu_monitor = None
    
    def analyze_cpu_data(self):
        """åˆ†æCPUæ•°æ®ï¼Œé‡‡é›†æ‰€æœ‰æ ¸æ€»æ•°å’Œæ‰€æœ‰æ ¸å¹³å‡ä½¿ç”¨ç‡"""
        if not self.monitoring_data['cpu']:
            return {}
        cpu_values = [usage for _, usage in self.monitoring_data['cpu']]
        stats = {
            'max_cpu': max(cpu_values),
            'min_cpu': min(cpu_values),
            'avg_cpu': sum(cpu_values) / len(cpu_values),
            'sample_count': len(cpu_values),
            'records': self.monitoring_data['cpu']
        }
        # è®¡ç®—P90å’ŒP95
        if len(cpu_values) > 0:
            sorted_values = sorted(cpu_values)
            p90_index = int(len(sorted_values) * 0.9)
            p95_index = int(len(sorted_values) * 0.95)
            stats['p90_cpu'] = sorted_values[p90_index] if p90_index < len(sorted_values) else sorted_values[-1]
            stats['p95_cpu'] = sorted_values[p95_index] if p95_index < len(sorted_values) else sorted_values[-1]
        else:
            stats['p90_cpu'] = 0
            stats['p95_cpu'] = 0
        # è®¡ç®—CPUå˜åŒ–ç‡
        if stats['min_cpu'] > 0:
            stats['cpu_change_rate'] = ((stats['max_cpu'] - stats['min_cpu']) / stats['min_cpu'] * 100)
        else:
            stats['cpu_change_rate'] = 0
        # è·å–æ‰€æœ‰æ ¸æ€»æ•°
        try:
            if not self.cpu_monitor:
                stats['cpu_cores'] = 0
                return stats
            cpu_cores = self._ssh_exec("nproc")
            if cpu_cores.isdigit():
                stats['cpu_cores'] = int(cpu_cores)
                print(f"âœ… [ç¡¬ä»¶ç›‘æ§] æœåŠ¡å™¨CPUæ€»æ ¸æ•°: {stats['cpu_cores']}")
            else:
                stats['cpu_cores'] = 0
                print(f"âŒ [ç¡¬ä»¶ç›‘æ§] è·å–CPUæ ¸æ•°å¤±è´¥ï¼Œè¿”å›: {cpu_cores}")
        except Exception as e:
            print(f"âŒ [ç¡¬ä»¶ç›‘æ§] è·å–CPUæ ¸æ•°å¼‚å¸¸: {e}")
            stats['cpu_cores'] = 0
        return stats

    def analyze_memory_data(self):
        """åˆ†æå†…å­˜æ•°æ®"""
        if not self.monitoring_data['memory']:
            return {}
        
        memory_usages = [info['usage_percent'] for _, info in self.monitoring_data['memory']]
        
        stats = {
            'max_memory': max(memory_usages),
            'min_memory': min(memory_usages),
            'avg_memory': sum(memory_usages) / len(memory_usages),
            'sample_count': len(memory_usages),
            'records': self.monitoring_data['memory']
        }
        
        # è®¡ç®—P90å’ŒP95
        if len(memory_usages) > 0:
            sorted_values = sorted(memory_usages)
            p90_index = int(len(sorted_values) * 0.9)
            p95_index = int(len(sorted_values) * 0.95)
            stats['p90_memory'] = sorted_values[p90_index] if p90_index < len(sorted_values) else sorted_values[-1]
            stats['p95_memory'] = sorted_values[p95_index] if p95_index < len(sorted_values) else sorted_values[-1]
        else:
            stats['p90_memory'] = 0
            stats['p95_memory'] = 0
        
        # è®¡ç®—å†…å­˜å˜åŒ–ç‡
        if stats['min_memory'] > 0:
            stats['memory_change_rate'] = ((stats['max_memory'] - stats['min_memory']) / stats['min_memory'] * 100)
        else:
            stats['memory_change_rate'] = 0
        
        return stats

    def analyze_disk_data(self):
        """åˆ†æç¡¬ç›˜æ•°æ®"""
        if not self.monitoring_data['disk']:
            return {}
        
        disk_usages = [info['usage_percent'] for _, info in self.monitoring_data['disk']]
        
        stats = {
            'max_disk': max(disk_usages),
            'min_disk': min(disk_usages),
            'avg_disk': sum(disk_usages) / len(disk_usages),
            'sample_count': len(disk_usages),
            'records': self.monitoring_data['disk']
        }
        
        # è®¡ç®—P90å’ŒP95
        if len(disk_usages) > 0:
            sorted_values = sorted(disk_usages)
            p90_index = int(len(sorted_values) * 0.9)
            p95_index = int(len(sorted_values) * 0.95)
            stats['p90_disk'] = sorted_values[p90_index] if p90_index < len(sorted_values) else sorted_values[-1]
            stats['p95_disk'] = sorted_values[p95_index] if p95_index < len(sorted_values) else sorted_values[-1]
        else:
            stats['p90_disk'] = 0
            stats['p95_disk'] = 0
        
        # è®¡ç®—ç¡¬ç›˜å˜åŒ–ç‡
        if stats['min_disk'] > 0:
            stats['disk_change_rate'] = ((stats['max_disk'] - stats['min_disk']) / stats['min_disk'] * 100)
        else:
            stats['disk_change_rate'] = 0
        
        return stats
    
    def run_jmeter_test(self, jmx_path, test_name, test_duration=60):
        """è¿è¡ŒJMETERæµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹æ‰§è¡ŒJMETERæµ‹è¯•: {test_name}")
        
        # ç”Ÿæˆç»“æœæ–‡ä»¶è·¯å¾„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        jtl_file = os.path.join(self.results_dir, f"{test_name}_{timestamp}.jtl")
        log_file = os.path.join(self.results_dir, f"{test_name}_{timestamp}.log")
        report_dir = os.path.join(self.results_dir, f"{test_name}_{timestamp}_report")
        
        # æ„å»ºJMETERå‘½ä»¤
        cmd = [
            self.jmeter_bin,
            "-n",  # éGUIæ¨¡å¼
            "-t", jmx_path,  # æµ‹è¯•è®¡åˆ’æ–‡ä»¶
            "-l", jtl_file,  # ç»“æœæ–‡ä»¶
            "-j", log_file,  # æ—¥å¿—æ–‡ä»¶
            "-e",  # ç”ŸæˆHTMLæŠ¥å‘Š
            "-o", report_dir  # æŠ¥å‘Šè¾“å‡ºç›®å½•
        ]
        
        print(f"ğŸ“‹ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = datetime.now()
        
        # å¯åŠ¨CPUç›‘æ§
        self.start_cpu_monitoring(test_duration + 30)  # å¤šç›‘æ§30ç§’
        
        try:
            # ä¿®å¤ï¼šå»æ‰cwdå‚æ•°ï¼Œç›´æ¥åœ¨å½“å‰ç›®å½•ä¸‹æ‰§è¡Œ
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                universal_newlines=True
            )
            
            # å®æ—¶è¾“å‡ºè¿›åº¦
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(f"   {output.strip()}")
            
            # ç­‰å¾…è¿›ç¨‹å®Œæˆ
            return_code = process.wait()
            
            # è®°å½•ç»“æŸæ—¶é—´
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # åœæ­¢CPUç›‘æ§
            self.stop_cpu_monitoring()
            
            if return_code == 0:
                print(f"âœ… JMETERæµ‹è¯•å®Œæˆ: {test_name}")
                print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {duration:.2f}ç§’")
                print(f"ğŸ“Š ç»“æœæ–‡ä»¶: {jtl_file}")
                print(f"ğŸ“ˆ æŠ¥å‘Šç›®å½•: {report_dir}")
                return True, jtl_file, report_dir, duration
            else:
                error_output = process.stderr.read()
                print(f"âŒ JMETERæµ‹è¯•å¤±è´¥: {test_name}")
                print(f"é”™è¯¯ä¿¡æ¯: {error_output}")
                return False, None, None, duration
                
        except Exception as e:
            print(f"âŒ æ‰§è¡ŒJMETERå‘½ä»¤å¤±è´¥: {e}")
            self.stop_cpu_monitoring()
            return False, None, None, 0
    
    def get_device_count_after(self):
        """è·å–æ³¨å†Œåçš„è®¾å¤‡æ•°é‡"""
        print("ğŸ“Š è·å–æ³¨å†Œåçš„è®¾å¤‡æ•°é‡...")
        try:
            service = DeviceQueryService(self.db_config)
            count = service.get_device_count('biz_device')
            service.close()
            print(f"ğŸ“ˆ æ³¨å†Œåè®¾å¤‡æ€»æ•°: {count}")
            return count
        except Exception as e:
            print(f"âŒ è·å–è®¾å¤‡æ•°é‡å¤±è´¥: {e}")
            return 0
    
    def analyze_jtl_file(self, jtl_file):
        """åˆ†æJTLæ–‡ä»¶ï¼Œç»Ÿè®¡æµ‹è¯•ç»“æœ"""
        print(f"ğŸ“Š åˆ†ææµ‹è¯•ç»“æœ: {jtl_file}")
        
        if not os.path.exists(jtl_file):
            print(f"âŒ JTLæ–‡ä»¶ä¸å­˜åœ¨: {jtl_file}")
            return {}
        
        stats = {
            'total_requests': 0,
            'success_count': 0,
            'fail_count': 0,
            'avg_response_time': 0,
            'min_response_time': float('inf'),
            'max_response_time': 0,
            'response_times': [],
            'jtl_duration_sec': 0,  # æ–°å¢ï¼šJTLæ–‡ä»¶çœŸå®æ‰§è¡Œæ—¶é—´
            'jtl_start_time': None,  # æ–°å¢ï¼šJTLå¼€å§‹æ—¶é—´
            'jtl_end_time': None,    # æ–°å¢ï¼šJTLç»“æŸæ—¶é—´
            # æ–°å¢ï¼šJMeteræ ‡å‡†å‚æ•°
            'response_time_std': 0,  # å“åº”æ—¶é—´æ ‡å‡†å·®
            'throughput': 0,         # ååé‡
            'received_kb_per_sec': 0, # æ¯ç§’æ¥æ”¶KBæ•°
            'sent_kb_per_sec': 0,    # æ¯ç§’å‘é€KBæ•°
            'avg_bytes': 0,          # å¹³å‡å­—èŠ‚æ•°
            'total_received_bytes': 0, # æ€»æ¥æ”¶å­—èŠ‚æ•°
            'total_sent_bytes': 0,   # æ€»å‘é€å­—èŠ‚æ•°
            'labels': set()          # æ ‡ç­¾é›†åˆ
        }
        
        try:
            timestamps = []  # å­˜å‚¨æ‰€æœ‰æ—¶é—´æˆ³
            bytes_received = []  # å­˜å‚¨æ¥æ”¶å­—èŠ‚æ•°
            bytes_sent = []      # å­˜å‚¨å‘é€å­—èŠ‚æ•°
            
            with open(jtl_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    stats['total_requests'] += 1
                    
                    # ç»Ÿè®¡æˆåŠŸ/å¤±è´¥
                    if row.get('success', '').lower() == 'true':
                        stats['success_count'] += 1
                    else:
                        stats['fail_count'] += 1
                    
                    # ç»Ÿè®¡å“åº”æ—¶é—´
                    try:
                        response_time = float(row.get('elapsed', 0))
                        stats['response_times'].append(response_time)
                        stats['min_response_time'] = min(stats['min_response_time'], response_time)
                        stats['max_response_time'] = max(stats['max_response_time'], response_time)
                    except (ValueError, TypeError):
                        pass
                    
                    # æ”¶é›†æ—¶é—´æˆ³ç”¨äºè®¡ç®—JTLæ‰§è¡Œæ—¶é—´
                    try:
                        timestamp = int(row.get('timeStamp', 0))
                        if timestamp > 0:
                            timestamps.append(timestamp)
                    except (ValueError, TypeError):
                        pass
                    
                    # æ”¶é›†å­—èŠ‚æ•°ä¿¡æ¯
                    try:
                        bytes_val = int(row.get('bytes', 0))
                        bytes_received.append(bytes_val)
                        stats['total_received_bytes'] += bytes_val
                    except (ValueError, TypeError):
                        pass
                    
                    try:
                        sent_bytes = int(row.get('sentBytes', 0))
                        bytes_sent.append(sent_bytes)
                        stats['total_sent_bytes'] += sent_bytes
                    except (ValueError, TypeError):
                        pass
                    
                    # æ”¶é›†æ ‡ç­¾
                    label = row.get('label', '')
                    if label:
                        stats['labels'].add(label)
            
            # è®¡ç®—JTLæ–‡ä»¶çœŸå®æ‰§è¡Œæ—¶é—´
            if timestamps:
                start_timestamp = min(timestamps)
                end_timestamp = max(timestamps)
                stats['jtl_duration_sec'] = (end_timestamp - start_timestamp) / 1000.0
                stats['jtl_start_time'] = datetime.fromtimestamp(start_timestamp / 1000.0).strftime('%H:%M:%S.%f')[:-3]
                stats['jtl_end_time'] = datetime.fromtimestamp(end_timestamp / 1000.0).strftime('%H:%M:%S.%f')[:-3]
            
            # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
            if stats['response_times']:
                stats['avg_response_time'] = sum(stats['response_times']) / len(stats['response_times'])
                stats['min_response_time'] = min(stats['response_times'])
                stats['max_response_time'] = max(stats['response_times'])
                
                # è®¡ç®—å“åº”æ—¶é—´æ ‡å‡†å·®
                mean_response = stats['avg_response_time']
                variance = sum((x - mean_response) ** 2 for x in stats['response_times']) / len(stats['response_times'])
                stats['response_time_std'] = variance ** 0.5
            
            # è®¡ç®—ååé‡
            if stats['jtl_duration_sec'] > 0:
                stats['throughput'] = stats['total_requests'] / stats['jtl_duration_sec']
            
            # è®¡ç®—ç½‘ç»œæŒ‡æ ‡
            if stats['jtl_duration_sec'] > 0:
                stats['received_kb_per_sec'] = (stats['total_received_bytes'] / 1024) / stats['jtl_duration_sec']
                stats['sent_kb_per_sec'] = (stats['total_sent_bytes'] / 1024) / stats['jtl_duration_sec']
            
            # è®¡ç®—å¹³å‡å­—èŠ‚æ•°
            if stats['total_requests'] > 0:
                stats['avg_bytes'] = stats['total_received_bytes'] / stats['total_requests']
            
            # è½¬æ¢æ ‡ç­¾é›†åˆä¸ºåˆ—è¡¨
            stats['labels'] = list(stats['labels'])
            
            print(f"ğŸ“ˆ æµ‹è¯•ç»Ÿè®¡:")
            print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
            print(f"   æˆåŠŸæ•°: {stats['success_count']}")
            print(f"   å¤±è´¥æ•°: {stats['fail_count']}")
            print(f"   æˆåŠŸç‡: {stats['success_count']/stats['total_requests']*100:.2f}%" if stats['total_requests'] > 0 else "   æˆåŠŸç‡: 0%")
            print(f"   é”™è¯¯ç‡: {stats['fail_count']/stats['total_requests']*100:.2f}%" if stats['total_requests'] > 0 else "   é”™è¯¯ç‡: 0%")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.2f}ms")
            print(f"   æœ€å°å“åº”æ—¶é—´: {stats['min_response_time']:.2f}ms")
            print(f"   æœ€å¤§å“åº”æ—¶é—´: {stats['max_response_time']:.2f}ms")
            print(f"   å“åº”æ—¶é—´æ ‡å‡†å·®: {stats['response_time_std']:.2f}ms")
            print(f"   ååé‡: {stats['throughput']:.2f} è¯·æ±‚/ç§’")
            print(f"   æ¯ç§’æ¥æ”¶KBæ•°: {stats['received_kb_per_sec']:.2f}")
            print(f"   æ¯ç§’å‘é€KBæ•°: {stats['sent_kb_per_sec']:.2f}")
            print(f"   å¹³å‡å­—èŠ‚æ•°: {stats['avg_bytes']:.2f}")
            print(f"   JTLæ‰§è¡Œæ—¶é—´: {stats['jtl_duration_sec']:.3f}ç§’")
            print(f"   JTLå¼€å§‹æ—¶é—´: {stats['jtl_start_time']}")
            print(f"   JTLç»“æŸæ—¶é—´: {stats['jtl_end_time']}")
            print(f"   æ ‡ç­¾: {', '.join(stats['labels'])}")
            
            return stats
            
        except Exception as e:
            print(f"âŒ åˆ†æJTLæ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def run_batch_test(self, thread_configs, test_type="register", iteration_num=1):
        """è¿è¡Œæ‰¹é‡æµ‹è¯•"""
        print(f"ğŸ¯ å¼€å§‹æ‰¹é‡{test_type}æµ‹è¯•")
        print("=" * 60)
        
        # æ£€æŸ¥å‰ç½®æ¡ä»¶
        self.check_prerequisites()
        
        # è·å–æ³¨å†Œå‰çš„è®¾å¤‡æ•°é‡
        count_before = self.get_device_count_before()
        
        # å­˜å‚¨æµ‹è¯•ç»“æœ
        test_results = []
        
        # æ‰§è¡Œæ¯ä¸ªé…ç½®çš„æµ‹è¯•
        for i, config in enumerate(thread_configs):
            thread_count = config['threads']
            loops = config.get('loops', 1)
            
            print(f"\n{'='*20} æµ‹è¯•é…ç½® {i+1}/{len(thread_configs)} {'='*20}")
            print(f"ğŸ§µ çº¿ç¨‹æ•°: {thread_count}")
            print(f"ğŸ”„ å¾ªç¯æ¬¡æ•°: {loops}")
            print(f"ğŸ“Š é¢„æœŸæ€»è¯·æ±‚æ•°: {thread_count * loops}")
            print(f"ğŸ¯ æµ‹è¯•ç±»å‹: {test_type}")
            
            # ä¿®æ”¹JMXæ–‡ä»¶
            modified_jmx = self.modify_jmx_threads(thread_count, loops)
            
            # ä¼°ç®—æµ‹è¯•æ—¶é•¿
            estimated_duration = max(60, thread_count * loops * 0.1)  # è‡³å°‘60ç§’
            
            # è¿è¡Œæµ‹è¯•
            test_name = f"iter{iteration_num}_{test_type}_{thread_count}threads_{loops}loops"
            success, jtl_file, report_dir, duration = self.run_jmeter_test(modified_jmx, test_name, estimated_duration)
            
            if success:
                # åˆ†ææµ‹è¯•ç»“æœ
                stats = self.analyze_jtl_file(jtl_file)
                
                # åˆ†æç³»ç»Ÿèµ„æºæ•°æ®
                cpu_stats = self.analyze_cpu_data()
                memory_stats = self.analyze_memory_data()
                disk_stats = self.analyze_disk_data()
                
                # è·å–æ³¨å†Œåçš„è®¾å¤‡æ•°é‡
                count_after = self.get_device_count_after()
                registered_count = count_after - count_before
                
                # è®°å½•æµ‹è¯•ç»“æœ
                result = {
                    'test_name': test_name,
                    'test_type': test_type,
                    'thread_count': thread_count,
                    'loops': loops,
                    'expected_requests': thread_count * loops,
                    'actual_requests': stats.get('total_requests', 0),
                    'success_count': stats.get('success_count', 0),
                    'fail_count': stats.get('fail_count', 0),
                    'success_rate': stats.get('success_count', 0) / stats.get('total_requests', 1) * 100 if stats.get('total_requests', 0) > 0 else 0,
                    'avg_response_time': stats.get('avg_response_time', 0),
                    'min_response_time': stats.get('min_response_time', 0),
                    'max_response_time': stats.get('max_response_time', 0),
                    'response_time_std': stats.get('response_time_std', 0),  # æ–°å¢ï¼šå“åº”æ—¶é—´æ ‡å‡†å·®
                    'duration': duration,  # è„šæœ¬æ‰§è¡Œæ—¶é—´ï¼ˆåŒ…å«è¿›ç¨‹å¼€é”€ï¼‰
                    'jtl_duration_sec': stats.get('jtl_duration_sec', 0),  # æ–°å¢ï¼šJTLæ–‡ä»¶çœŸå®æ‰§è¡Œæ—¶é—´
                    'jtl_start_time': stats.get('jtl_start_time', ''),  # æ–°å¢ï¼šJTLå¼€å§‹æ—¶é—´
                    'jtl_end_time': stats.get('jtl_end_time', ''),  # æ–°å¢ï¼šJTLç»“æŸæ—¶é—´
                    # æ–°å¢ï¼šJMeteræ ‡å‡†å‚æ•°
                    'throughput': stats.get('throughput', 0),
                    'received_kb_per_sec': stats.get('received_kb_per_sec', 0),
                    'sent_kb_per_sec': stats.get('sent_kb_per_sec', 0),
                    'avg_bytes': stats.get('avg_bytes', 0),
                    'labels': stats.get('labels', []),
                    'count_before': count_before,
                    'count_after': count_after,
                    'registered_count': registered_count,
                    'jtl_file': jtl_file,
                    'report_dir': report_dir,
                    'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    # CPUç›‘æ§æ•°æ®
                    'cpu_max': cpu_stats.get('max_cpu', 0),
                    'cpu_min': cpu_stats.get('min_cpu', 0),
                    'cpu_avg': cpu_stats.get('avg_cpu', 0),
                    'cpu_p90': cpu_stats.get('p90_cpu', 0),
                    'cpu_p95': cpu_stats.get('p95_cpu', 0),
                    'cpu_change_rate': cpu_stats.get('cpu_change_rate', 0),
                    'cpu_sample_count': cpu_stats.get('sample_count', 0),
                    # æ–°å¢ï¼šCPUè¯¦ç»†ä¿¡æ¯
                    'cpu_cores': cpu_stats.get('cpu_cores', 0),
                    'load_1min': cpu_stats.get('load_1min', 0),
                    'load_5min': cpu_stats.get('load_5min', 0),
                    'load_15min': cpu_stats.get('load_15min', 0),
                    'cpu_temperature': cpu_stats.get('cpu_temperature', 0),
                    'process_count': cpu_stats.get('process_count', 0),
                    'system_thread_count': cpu_stats.get('thread_count', 0),  # ä¿®å¤ï¼šé‡å‘½åä¸ºsystem_thread_count
                    'context_switches': cpu_stats.get('context_switches', 0),
                    # å†…å­˜ç›‘æ§æ•°æ®
                    'memory_max': memory_stats.get('max_memory', 0),
                    'memory_min': memory_stats.get('min_memory', 0),
                    'memory_avg': memory_stats.get('avg_memory', 0),
                    'memory_p90': memory_stats.get('p90_memory', 0),
                    'memory_p95': memory_stats.get('p95_memory', 0),
                    'memory_change_rate': memory_stats.get('memory_change_rate', 0),
                    'memory_sample_count': memory_stats.get('sample_count', 0),
                    # ç¡¬ç›˜ç›‘æ§æ•°æ®
                    'disk_max': disk_stats.get('max_disk', 0),
                    'disk_min': disk_stats.get('min_disk', 0),
                    'disk_avg': disk_stats.get('avg_disk', 0),
                    'disk_p90': disk_stats.get('p90_disk', 0),
                    'disk_p95': disk_stats.get('p95_disk', 0),
                    'disk_change_rate': disk_stats.get('disk_change_rate', 0),
                    'disk_sample_count': disk_stats.get('sample_count', 0)
                }
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°resultä¸­çš„thread_count
                print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - result['thread_count']: {result['thread_count']}")
                
                test_results.append(result)
                
                print(f"âœ… æµ‹è¯•å®Œæˆ: {test_name}")
                print(f"ğŸ“Š å®é™…æ³¨å†Œæ•°é‡: {registered_count}")
                print(f"ğŸ“ˆ æ³¨å†ŒæˆåŠŸç‡: {registered_count/(thread_count*loops)*100:.2f}%" if thread_count*loops > 0 else "ğŸ“ˆ æ³¨å†ŒæˆåŠŸç‡: 0%")
                print(f"ğŸ–¥ï¸  CPUä½¿ç”¨ç‡: æœ€å¤§={cpu_stats.get('max_cpu', 0):.1f}%, å¹³å‡={cpu_stats.get('avg_cpu', 0):.1f}%")
                print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨ç‡: æœ€å¤§={memory_stats.get('max_memory', 0):.1f}%, å¹³å‡={memory_stats.get('avg_memory', 0):.1f}%")
                print(f"ğŸ’¿ ç¡¬ç›˜ä½¿ç”¨ç‡: æœ€å¤§={disk_stats.get('max_disk', 0):.1f}%, å¹³å‡={disk_stats.get('avg_disk', 0):.1f}%")
                
                # æ›´æ–°åŸºå‡†æ•°é‡
                count_before = count_after
                
            else:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {test_name}")
            
            # æµ‹è¯•é—´éš”
            if i < len(thread_configs) - 1:
                print(f"\nâ³ ç­‰å¾…10ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")
                time.sleep(10)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_summary_report(test_results, f"{test_type}_iterative_summary")
        
        return test_results
    
    def generate_summary_report(self, test_results, test_type):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
        
        # å®šä¹‰å­—æ®µé‡è¦çº§åˆ«æ’åºï¼ˆé‡è¦ç¨‹åº¦ä»é«˜åˆ°ä½ï¼‰
        field_priority = [
            # æ ¸å¿ƒæµ‹è¯•ä¿¡æ¯
            'æµ‹è¯•åç§°', 'æµ‹è¯•ç±»å‹', 'çº¿ç¨‹æ•°', 'å¾ªç¯æ¬¡æ•°', 'é¢„æœŸè¯·æ±‚æ•°', 'å®é™…è¯·æ±‚æ•°',
            'æˆåŠŸæ•°', 'å¤±è´¥æ•°', 'æˆåŠŸç‡(%)', 'é”™è¯¯ç‡(%)',
            # å“åº”æ—¶é—´æŒ‡æ ‡
            'å¹³å‡å“åº”æ—¶é—´(ms)', 'æœ€å°å“åº”æ—¶é—´(ms)', 'æœ€å¤§å“åº”æ—¶é—´(ms)', 'å“åº”æ—¶é—´æ ‡å‡†å·®(ms)',
            # æ‰§è¡Œæ—¶é—´
            'è„šæœ¬æ‰§è¡Œæ—¶é—´(ç§’)', 'JTLæ‰§è¡Œæ—¶é—´(ç§’)', 'JTLå¼€å§‹æ—¶é—´', 'JTLç»“æŸæ—¶é—´',
            # ååé‡æŒ‡æ ‡
            'ååé‡(è¯·æ±‚/ç§’)', 'æ¯ç§’æ¥æ”¶KBæ•°', 'æ¯ç§’å‘é€KBæ•°', 'å¹³å‡å­—èŠ‚æ•°',
            # æ³¨å†Œç»“æœ
            'æ³¨å†Œå‰è®¾å¤‡æ•°', 'æ³¨å†Œåè®¾å¤‡æ•°', 'å®é™…æ³¨å†Œæ•°', 'æ³¨å†ŒæˆåŠŸç‡(%)',
            # CPUç›‘æ§ï¼ˆæŒ‰é‡è¦ç¨‹åº¦æ’åºï¼‰
            'CPUå¹³å‡å€¼(%)', 'CPUæœ€å¤§å€¼(%)', 'CPU_P95(%)', 'CPU_P90(%)', 'CPUæœ€å°å€¼(%)', 'CPUå˜åŒ–ç‡(%)', 'CPUé‡‡æ ·ç‚¹æ•°',
            'CPUæ ¸å¿ƒæ•°', 'ç³»ç»Ÿè´Ÿè½½_1åˆ†é’Ÿ', 'ç³»ç»Ÿè´Ÿè½½_5åˆ†é’Ÿ', 'ç³»ç»Ÿè´Ÿè½½_15åˆ†é’Ÿ', 'CPUæ¸©åº¦(Â°C)', 'è¿›ç¨‹æ•°', 'ç³»ç»Ÿçº¿ç¨‹æ•°', 'ä¸Šä¸‹æ–‡åˆ‡æ¢æ•°',
            # å†…å­˜ç›‘æ§ï¼ˆæŒ‰é‡è¦ç¨‹åº¦æ’åºï¼‰
            'å†…å­˜å¹³å‡å€¼(%)', 'å†…å­˜æœ€å¤§å€¼(%)', 'å†…å­˜_P95(%)', 'å†…å­˜_P90(%)', 'å†…å­˜æœ€å°å€¼(%)', 'å†…å­˜å˜åŒ–ç‡(%)', 'å†…å­˜é‡‡æ ·ç‚¹æ•°',
            # ç¡¬ç›˜ç›‘æ§ï¼ˆæŒ‰é‡è¦ç¨‹åº¦æ’åºï¼‰
            'ç¡¬ç›˜å¹³å‡å€¼(%)', 'ç¡¬ç›˜æœ€å¤§å€¼(%)', 'ç¡¬ç›˜_P95(%)', 'ç¡¬ç›˜_P90(%)', 'ç¡¬ç›˜æœ€å°å€¼(%)', 'ç¡¬ç›˜å˜åŒ–ç‡(%)', 'ç¡¬ç›˜é‡‡æ ·ç‚¹æ•°',
            # æ–‡ä»¶ä¿¡æ¯
            'JTLæ–‡ä»¶', 'æŠ¥å‘Šç›®å½•', 'æµ‹è¯•æ—¶é—´'
        ]
        
        # ç”Ÿæˆæ¨ªæ ‡é¢˜æŠ¥å‘Šï¼ˆæ ‡å‡†CSVæ ¼å¼ï¼‰
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_file_horizontal = os.path.join(self.results_dir, f"enhanced_{test_type}_summary_horizontal_{timestamp}.csv")
        
        with open(csv_file_horizontal, 'w', newline='', encoding='utf-8') as f:
            # æŒ‰é‡è¦çº§åˆ«æ’åºå­—æ®µ
            ordered_fieldnames = [field for field in field_priority if field in self._get_all_fieldnames()]
            
            writer = csv.DictWriter(f, fieldnames=ordered_fieldnames)
            writer.writeheader()
            
            for result in test_results:
                row_data = self._prepare_report_row(result, ordered_fieldnames)
                writer.writerow(row_data)
        
        print(f"ğŸ“Š æ¨ªæ ‡é¢˜CSVæŠ¥å‘Šå·²ç”Ÿæˆ: {csv_file_horizontal}")
        
        # ç”Ÿæˆåˆ—æ ‡é¢˜æŠ¥å‘Šï¼ˆè½¬ç½®æ ¼å¼ï¼‰
        csv_file_vertical = os.path.join(self.results_dir, f"enhanced_{test_type}_summary_vertical_{timestamp}.csv")
        
        with open(csv_file_vertical, 'w', newline='', encoding='utf-8') as f:
            # æŒ‰é‡è¦çº§åˆ«æ’åºå­—æ®µ
            ordered_fieldnames = [field for field in field_priority if field in self._get_all_fieldnames()]
            
            writer = csv.writer(f)
            
            # å†™å…¥æ ‡é¢˜è¡Œ
            writer.writerow(['æŒ‡æ ‡åç§°'] + [result['test_name'] for result in test_results])
            
            # æŒ‰é‡è¦çº§åˆ«å†™å…¥æ¯è¡Œæ•°æ®
            for field in ordered_fieldnames:
                row_data = [field]
                for result in test_results:
                    value = self._get_field_value(result, field)
                    row_data.append(value)
                writer.writerow(row_data)
        
        print(f"ğŸ“Š åˆ—æ ‡é¢˜CSVæŠ¥å‘Šå·²ç”Ÿæˆ: {csv_file_vertical}")
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        json_file = os.path.join(self.results_dir, f"enhanced_{test_type}_summary_{timestamp}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ JSONæŠ¥å‘Šå·²ç”Ÿæˆ: {json_file}")
        
        # æ‰“å°æ€»ç»“
        self._print_summary_report(test_results)
        
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {self.results_dir}")
        print(f"ğŸ“„ æ¨ªæ ‡é¢˜æŠ¥å‘Š: {csv_file_horizontal}")
        print(f"ğŸ“„ åˆ—æ ‡é¢˜æŠ¥å‘Š: {csv_file_vertical}")
        print(f"ğŸ“„ JSONæŠ¥å‘Š: {json_file}")
    
    def _get_all_fieldnames(self):
        """è·å–æ‰€æœ‰å¯èƒ½çš„å­—æ®µå"""
        return [
            'æµ‹è¯•åç§°', 'æµ‹è¯•ç±»å‹', 'çº¿ç¨‹æ•°', 'å¾ªç¯æ¬¡æ•°', 'é¢„æœŸè¯·æ±‚æ•°', 'å®é™…è¯·æ±‚æ•°',
            'æˆåŠŸæ•°', 'å¤±è´¥æ•°', 'æˆåŠŸç‡(%)', 'é”™è¯¯ç‡(%)',
            'å¹³å‡å“åº”æ—¶é—´(ms)', 'æœ€å°å“åº”æ—¶é—´(ms)', 'æœ€å¤§å“åº”æ—¶é—´(ms)', 'å“åº”æ—¶é—´æ ‡å‡†å·®(ms)',
            'è„šæœ¬æ‰§è¡Œæ—¶é—´(ç§’)', 'JTLæ‰§è¡Œæ—¶é—´(ç§’)', 'JTLå¼€å§‹æ—¶é—´', 'JTLç»“æŸæ—¶é—´',
            'ååé‡(è¯·æ±‚/ç§’)', 'æ¯ç§’æ¥æ”¶KBæ•°', 'æ¯ç§’å‘é€KBæ•°', 'å¹³å‡å­—èŠ‚æ•°',
            'æ³¨å†Œå‰è®¾å¤‡æ•°', 'æ³¨å†Œåè®¾å¤‡æ•°', 'å®é™…æ³¨å†Œæ•°', 'æ³¨å†ŒæˆåŠŸç‡(%)',
            'CPUå¹³å‡å€¼(%)', 'CPUæœ€å¤§å€¼(%)', 'CPU_P95(%)', 'CPU_P90(%)', 'CPUæœ€å°å€¼(%)', 'CPUå˜åŒ–ç‡(%)', 'CPUé‡‡æ ·ç‚¹æ•°',
            'CPUæ ¸å¿ƒæ•°', 'ç³»ç»Ÿè´Ÿè½½_1åˆ†é’Ÿ', 'ç³»ç»Ÿè´Ÿè½½_5åˆ†é’Ÿ', 'ç³»ç»Ÿè´Ÿè½½_15åˆ†é’Ÿ', 'CPUæ¸©åº¦(Â°C)', 'è¿›ç¨‹æ•°', 'ç³»ç»Ÿçº¿ç¨‹æ•°', 'ä¸Šä¸‹æ–‡åˆ‡æ¢æ•°',
            'å†…å­˜å¹³å‡å€¼(%)', 'å†…å­˜æœ€å¤§å€¼(%)', 'å†…å­˜_P95(%)', 'å†…å­˜_P90(%)', 'å†…å­˜æœ€å°å€¼(%)', 'å†…å­˜å˜åŒ–ç‡(%)', 'å†…å­˜é‡‡æ ·ç‚¹æ•°',
            'ç¡¬ç›˜å¹³å‡å€¼(%)', 'ç¡¬ç›˜æœ€å¤§å€¼(%)', 'ç¡¬ç›˜_P95(%)', 'ç¡¬ç›˜_P90(%)', 'ç¡¬ç›˜æœ€å°å€¼(%)', 'ç¡¬ç›˜å˜åŒ–ç‡(%)', 'ç¡¬ç›˜é‡‡æ ·ç‚¹æ•°',
            'JTLæ–‡ä»¶', 'æŠ¥å‘Šç›®å½•', 'æµ‹è¯•æ—¶é—´'
        ]
    
    def _prepare_report_row(self, result, fieldnames):
        """å‡†å¤‡æŠ¥å‘Šè¡Œæ•°æ®"""
        row_data = {}
        for field in fieldnames:
            row_data[field] = self._get_field_value(result, field)
        return row_data
    
    def _get_field_value(self, result, field):
        """è·å–å­—æ®µå€¼"""
        field_mapping = {
            'æµ‹è¯•åç§°': result['test_name'],
            'æµ‹è¯•ç±»å‹': result['test_type'],
            'çº¿ç¨‹æ•°': result['thread_count'],
            'å¾ªç¯æ¬¡æ•°': result['loops'],
            'é¢„æœŸè¯·æ±‚æ•°': result['expected_requests'],
            'å®é™…è¯·æ±‚æ•°': result['actual_requests'],
            'æˆåŠŸæ•°': result['success_count'],
            'å¤±è´¥æ•°': result['fail_count'],
            'æˆåŠŸç‡(%)': f"{result['success_rate']:.2f}",
            'é”™è¯¯ç‡(%)': f"{100 - result['success_rate']:.2f}",
            'å¹³å‡å“åº”æ—¶é—´(ms)': f"{result['avg_response_time']:.2f}",
            'æœ€å°å“åº”æ—¶é—´(ms)': f"{result['min_response_time']:.2f}" if result['min_response_time'] != float('inf') else "0.00",
            'æœ€å¤§å“åº”æ—¶é—´(ms)': f"{result['max_response_time']:.2f}",
            'å“åº”æ—¶é—´æ ‡å‡†å·®(ms)': f"{result.get('response_time_std', 0):.2f}",
            'è„šæœ¬æ‰§è¡Œæ—¶é—´(ç§’)': f"{result['duration']:.2f}",
            'JTLæ‰§è¡Œæ—¶é—´(ç§’)': f"{result['jtl_duration_sec']:.3f}",
            'JTLå¼€å§‹æ—¶é—´': result['jtl_start_time'] if result['jtl_start_time'] else "",
            'JTLç»“æŸæ—¶é—´': result['jtl_end_time'] if result['jtl_end_time'] else "",
            'ååé‡(è¯·æ±‚/ç§’)': f"{result.get('throughput', 0):.2f}",
            'æ¯ç§’æ¥æ”¶KBæ•°': f"{result.get('received_kb_per_sec', 0):.2f}",
            'æ¯ç§’å‘é€KBæ•°': f"{result.get('sent_kb_per_sec', 0):.2f}",
            'å¹³å‡å­—èŠ‚æ•°': f"{result.get('avg_bytes', 0):.2f}",
            'æ³¨å†Œå‰è®¾å¤‡æ•°': result['count_before'],
            'æ³¨å†Œåè®¾å¤‡æ•°': result['count_after'],
            'å®é™…æ³¨å†Œæ•°': result['registered_count'],
            'æ³¨å†ŒæˆåŠŸç‡(%)': f"{result['registered_count']/result['expected_requests']*100:.2f}" if result['expected_requests'] > 0 else "0.00",
            'CPUå¹³å‡å€¼(%)': f"{result['cpu_avg']:.2f}",
            'CPUæœ€å¤§å€¼(%)': f"{result['cpu_max']:.2f}",
            'CPU_P95(%)': f"{result['cpu_p95']:.2f}",
            'CPU_P90(%)': f"{result['cpu_p90']:.2f}",
            'CPUæœ€å°å€¼(%)': f"{result['cpu_min']:.2f}",
            'CPUå˜åŒ–ç‡(%)': f"{result['cpu_change_rate']:.2f}",
            'CPUé‡‡æ ·ç‚¹æ•°': result['cpu_sample_count'],
            'CPUæ ¸å¿ƒæ•°': result.get('cpu_cores', 0),
            'ç³»ç»Ÿè´Ÿè½½_1åˆ†é’Ÿ': f"{result.get('load_1min', 0):.2f}",
            'ç³»ç»Ÿè´Ÿè½½_5åˆ†é’Ÿ': f"{result.get('load_5min', 0):.2f}",
            'ç³»ç»Ÿè´Ÿè½½_15åˆ†é’Ÿ': f"{result.get('load_15min', 0):.2f}",
            'CPUæ¸©åº¦(Â°C)': f"{result.get('cpu_temperature', 0):.1f}",
            'è¿›ç¨‹æ•°': result.get('process_count', 0),
            'ç³»ç»Ÿçº¿ç¨‹æ•°': result.get('system_thread_count', 0),  # ä¿®å¤ï¼šé‡å‘½åä¸ºç³»ç»Ÿçº¿ç¨‹æ•°
            'ä¸Šä¸‹æ–‡åˆ‡æ¢æ•°': result.get('context_switches', 0),
            'å†…å­˜å¹³å‡å€¼(%)': f"{result['memory_avg']:.2f}",
            'å†…å­˜æœ€å¤§å€¼(%)': f"{result['memory_max']:.2f}",
            'å†…å­˜_P95(%)': f"{result['memory_p95']:.2f}",
            'å†…å­˜_P90(%)': f"{result['memory_p90']:.2f}",
            'å†…å­˜æœ€å°å€¼(%)': f"{result['memory_min']:.2f}",
            'å†…å­˜å˜åŒ–ç‡(%)': f"{result['memory_change_rate']:.2f}",
            'å†…å­˜é‡‡æ ·ç‚¹æ•°': result['memory_sample_count'],
            'ç¡¬ç›˜å¹³å‡å€¼(%)': f"{result['disk_avg']:.2f}",
            'ç¡¬ç›˜æœ€å¤§å€¼(%)': f"{result['disk_max']:.2f}",
            'ç¡¬ç›˜_P95(%)': f"{result['disk_p95']:.2f}",
            'ç¡¬ç›˜_P90(%)': f"{result['disk_p90']:.2f}",
            'ç¡¬ç›˜æœ€å°å€¼(%)': f"{result['disk_min']:.2f}",
            'ç¡¬ç›˜å˜åŒ–ç‡(%)': f"{result['disk_change_rate']:.2f}",
            'ç¡¬ç›˜é‡‡æ ·ç‚¹æ•°': result['disk_sample_count'],
            'JTLæ–‡ä»¶': result['jtl_file'],
            'æŠ¥å‘Šç›®å½•': result['report_dir'],
            'æµ‹è¯•æ—¶é—´': result['timestamp']
        }
        
        return field_mapping.get(field, '')
    
    def _print_summary_report(self, test_results):
        """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
        print("\n" + "="*60)
        print(f"ğŸ¯ æ‰¹é‡æµ‹è¯•æ€»ç»“")
        print("="*60)
        
        total_expected = sum(r['expected_requests'] for r in test_results)
        total_actual = sum(r['actual_requests'] for r in test_results)
        total_success = sum(r['success_count'] for r in test_results)
        total_registered = sum(r['registered_count'] for r in test_results)
        
        # CPUç»Ÿè®¡
        all_cpu_avg = [r['cpu_avg'] for r in test_results if r['cpu_avg'] > 0]
        avg_cpu_usage = sum(all_cpu_avg) / len(all_cpu_avg) if all_cpu_avg else 0
        max_cpu_usage = max([r['cpu_max'] for r in test_results]) if test_results else 0
        
        # å†…å­˜ç»Ÿè®¡
        all_memory_avg = [r['memory_avg'] for r in test_results if r['memory_avg'] > 0]
        avg_memory_usage = sum(all_memory_avg) / len(all_memory_avg) if all_memory_avg else 0
        max_memory_usage = max([r['memory_max'] for r in test_results]) if test_results else 0
        
        # ç¡¬ç›˜ç»Ÿè®¡
        all_disk_avg = [r['disk_avg'] for r in test_results if r['disk_avg'] > 0]
        avg_disk_usage = sum(all_disk_avg) / len(all_disk_avg) if all_disk_avg else 0
        max_disk_usage = max([r['disk_max'] for r in test_results]) if test_results else 0
        
        print(f"ğŸ“Š æ€»é¢„æœŸè¯·æ±‚æ•°: {total_expected}")
        print(f"ğŸ“Š æ€»å®é™…è¯·æ±‚æ•°: {total_actual}")
        print(f"ğŸ“Š æ€»æˆåŠŸè¯·æ±‚æ•°: {total_success}")
        print(f"ğŸ“Š æ€»æ³¨å†Œè®¾å¤‡æ•°: {total_registered}")
        print(f"ğŸ“ˆ æ•´ä½“æˆåŠŸç‡: {total_success/total_actual*100:.2f}%" if total_actual > 0 else "ğŸ“ˆ æ•´ä½“æˆåŠŸç‡: 0%")
        print(f"ğŸ“ˆ æ•´ä½“æ³¨å†Œç‡: {total_registered/total_expected*100:.2f}%" if total_expected > 0 else "ğŸ“ˆ æ•´ä½“æ³¨å†Œç‡: 0%")
        print(f"ğŸ–¥ï¸  å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu_usage:.2f}%")
        print(f"ğŸ–¥ï¸  æœ€å¤§CPUä½¿ç”¨ç‡: {max_cpu_usage:.2f}%")
        print(f"ğŸ’¾ å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory_usage:.2f}%")
        print(f"ğŸ’¾ æœ€å¤§å†…å­˜ä½¿ç”¨ç‡: {max_memory_usage:.2f}%")
        print(f"ğŸ’¿ å¹³å‡ç¡¬ç›˜ä½¿ç”¨ç‡: {avg_disk_usage:.2f}%")
        print(f"ğŸ’¿ æœ€å¤§ç¡¬ç›˜ä½¿ç”¨ç‡: {max_disk_usage:.2f}%")
        
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {self.results_dir}")

    def run_csv_sharding_batch_test(self, csv_dir, csv_pattern, thread_count=5000, loops=1):
        """
        è‡ªåŠ¨å¾ªç¯20æ¬¡ï¼Œæ¯æ¬¡åˆ‡æ¢CSVæ–‡ä»¶ï¼Œçº¿ç¨‹æ•°5000ï¼Œå¾ªç¯1æ¬¡ï¼Œè‡ªåŠ¨è°ƒç”¨JMeteræ³¨å†Œã€‚
        :param csv_dir: CSVæ–‡ä»¶ç›®å½•
        :param csv_pattern: CSVæ–‡ä»¶é€šé…ç¬¦ï¼Œå¦‚'new_devices_part_*.csv'
        :param thread_count: æ¯æ‰¹çº¿ç¨‹æ•°
        :param loops: æ¯æ‰¹å¾ªç¯æ¬¡æ•°
        """
        print(f"\nğŸš€ å¯åŠ¨åˆ†ç‰‡æ‰¹é‡æ³¨å†Œæµ‹è¯•ï¼Œç›®å½•: {csv_dir}ï¼Œæ¨¡å¼: {csv_pattern}")
        csv_files = sorted(glob.glob(os.path.join(csv_dir, csv_pattern)))
        if not csv_files:
            print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•åˆ†ç‰‡CSVæ–‡ä»¶: {csv_pattern}")
            return
        print(f"ğŸ“‚ å…±æ£€æµ‹åˆ°{len(csv_files)}ä¸ªåˆ†ç‰‡CSVæ–‡ä»¶")
        all_results = []
        for idx, csv_file in enumerate(csv_files):
            print(f"\n{'='*20} åˆ†ç‰‡ {idx+1}/{len(csv_files)} {'='*20}")
            self.csv_file = csv_file  # åˆ‡æ¢å½“å‰CSV
            # ä¿®æ”¹JMXæ–‡ä»¶ï¼Œçº¿ç¨‹æ•°5000ï¼Œå¾ªç¯1æ¬¡ï¼ŒCSVè·¯å¾„ä¸ºå½“å‰åˆ†ç‰‡
            modified_jmx = self.modify_jmx_threads(thread_count, loops)
            test_name = f"shard_{idx+1:02d}_{thread_count}threads_{loops}loops"
            estimated_duration = max(60, thread_count * loops * 0.1)
            success, jtl_file, report_dir, duration = self.run_jmeter_test(modified_jmx, test_name, estimated_duration)
            if success:
                stats = self.analyze_jtl_file(jtl_file)
                cpu_stats = self.analyze_cpu_data()
                memory_stats = self.analyze_memory_data()
                disk_stats = self.analyze_disk_data()
                count_before = self.get_device_count_before()
                count_after = self.get_device_count_after()
                registered_count = count_after - count_before
                result = {
                    'test_name': test_name,
                    'thread_count': thread_count,
                    'loops': loops,
                    'csv_file': csv_file,
                    'actual_requests': stats.get('total_requests', 0),
                    'success_count': stats.get('success_count', 0),
                    'fail_count': stats.get('fail_count', 0),
                    'success_rate': stats.get('success_count', 0) / stats.get('total_requests', 1) * 100 if stats.get('total_requests', 0) > 0 else 0,
                    'avg_response_time': stats.get('avg_response_time', 0),
                    'min_response_time': stats.get('min_response_time', 0),
                    'max_response_time': stats.get('max_response_time', 0),
                    'duration': duration,
                    'registered_count': registered_count,
                    'jtl_file': jtl_file,
                    'report_dir': report_dir,
                    'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'cpu_max': cpu_stats.get('max_cpu', 0),
                    'cpu_min': cpu_stats.get('min_cpu', 0),
                    'cpu_avg': cpu_stats.get('avg_cpu', 0),
                    'cpu_p90': cpu_stats.get('p90_cpu', 0),
                    'cpu_p95': cpu_stats.get('p95_cpu', 0),
                    'cpu_change_rate': cpu_stats.get('cpu_change_rate', 0),
                    'cpu_sample_count': cpu_stats.get('sample_count', 0),
                    'memory_max': memory_stats.get('max_memory', 0),
                    'memory_min': memory_stats.get('min_memory', 0),
                    'memory_avg': memory_stats.get('avg_memory', 0),
                    'memory_p90': memory_stats.get('p90_memory', 0),
                    'memory_p95': memory_stats.get('p95_memory', 0),
                    'memory_change_rate': memory_stats.get('memory_change_rate', 0),
                    'memory_sample_count': memory_stats.get('sample_count', 0),
                    'disk_max': disk_stats.get('max_disk', 0),
                    'disk_min': disk_stats.get('min_disk', 0),
                    'disk_avg': disk_stats.get('avg_disk', 0),
                    'disk_p90': disk_stats.get('p90_disk', 0),
                    'disk_p95': disk_stats.get('p95_disk', 0),
                    'disk_change_rate': disk_stats.get('disk_change_rate', 0),
                    'disk_sample_count': disk_stats.get('sample_count', 0)
                }
                all_results.append(result)
                print(f"âœ… åˆ†ç‰‡{idx+1}æ³¨å†Œå®Œæˆï¼Œæ³¨å†Œæ•°: {registered_count}")
            else:
                print(f"âŒ åˆ†ç‰‡{idx+1}æ³¨å†Œå¤±è´¥")
            if idx < len(csv_files) - 1:
                print("â³ ç­‰å¾…10ç§’åç»§ç»­ä¸‹ä¸€åˆ†ç‰‡...")
                time.sleep(10)
        # æ±‡æ€»æŠ¥å‘Š
        self.generate_summary_report(all_results, "sharding_register")
        print("\nğŸ‰ åˆ†ç‰‡æ‰¹é‡æ³¨å†Œå…¨éƒ¨å®Œæˆï¼")

    def run_batch_login_test(self, loop_configs=None):
        """
        æ‰¹é‡ç™»å½•æµ‹è¯•ï¼šå›ºå®šçº¿ç¨‹æ•°500ï¼Œæµ‹è¯•ä¸åŒå¾ªç¯æ¬¡æ•°
        Args:
            loop_configs: å¾ªç¯æ¬¡æ•°åˆ—è¡¨ï¼Œé»˜è®¤[1, 2, 5, 10, 20]
        """
        if loop_configs is None:
            loop_configs = [1, 2, 5, 10, 20]
        
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡ç™»å½•æµ‹è¯•")
        print(f"ğŸ“Š å›ºå®šçº¿ç¨‹æ•°: {500}")
        print(f"ğŸ”„ å¾ªç¯æ¬¡æ•°é…ç½®: {loop_configs}")
        
        # æ£€æŸ¥å‰ç½®æ¡ä»¶ï¼ˆç™»å½•æµ‹è¯•è·³è¿‡CSVæ–‡ä»¶æ£€æŸ¥ï¼‰
        if not self.check_prerequisites():
            print("âŒ å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
            return []
        
        # æ„å»ºæµ‹è¯•é…ç½®ï¼Œå¼ºåˆ¶ä½¿ç”¨500çº¿ç¨‹
        thread_configs = []
        for loops in loop_configs:
            thread_configs.append({
                'threads': 500,  # å›ºå®šçº¿ç¨‹æ•°500
                'loops': loops
            })
        
        # è·å–æµ‹è¯•å‰è®¾å¤‡æ•°é‡
        count_before = self.get_device_count_before()
        print(f"ğŸ“ˆ æµ‹è¯•å‰è®¾å¤‡æ€»æ•°: {count_before}")
        
        # å¤ç”¨ç°æœ‰çš„æ‰¹é‡æµ‹è¯•æ–¹æ³•ï¼Œä½†ä¼ å…¥å›ºå®šçº¿ç¨‹æ•°çš„é…ç½®
        test_results = self.run_batch_test(thread_configs, test_type="login", iteration_num=1)
        
        # ç”Ÿæˆä¸“é—¨çš„ç™»å½•æµ‹è¯•æŠ¥å‘Š
        self.generate_login_summary_report(test_results)
        
        return test_results
    
    def generate_login_summary_report(self, test_results):
        """ç”Ÿæˆä¸“é—¨çš„ç™»å½•æµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç™»å½•æµ‹è¯•ä¸“ç”¨æŠ¥å‘Š...")
        
        # å®šä¹‰å­—æ®µé‡è¦çº§åˆ«æ’åºï¼ˆé‡è¦ç¨‹åº¦ä»é«˜åˆ°ä½ï¼‰
        field_priority = [
            # æ ¸å¿ƒæµ‹è¯•ä¿¡æ¯
            'æµ‹è¯•åç§°', 'æµ‹è¯•ç±»å‹', 'çº¿ç¨‹æ•°', 'å¾ªç¯æ¬¡æ•°', 'é¢„æœŸè¯·æ±‚æ•°', 'å®é™…è¯·æ±‚æ•°',
            'æˆåŠŸæ•°', 'å¤±è´¥æ•°', 'æˆåŠŸç‡(%)', 'é”™è¯¯ç‡(%)',
            # å“åº”æ—¶é—´æŒ‡æ ‡
            'å¹³å‡å“åº”æ—¶é—´(ms)', 'æœ€å°å“åº”æ—¶é—´(ms)', 'æœ€å¤§å“åº”æ—¶é—´(ms)', 'å“åº”æ—¶é—´æ ‡å‡†å·®(ms)',
            # æ‰§è¡Œæ—¶é—´
            'è„šæœ¬æ‰§è¡Œæ—¶é—´(ç§’)', 'JTLæ‰§è¡Œæ—¶é—´(ç§’)', 'JTLå¼€å§‹æ—¶é—´', 'JTLç»“æŸæ—¶é—´',
            # ååé‡æŒ‡æ ‡
            'ååé‡(è¯·æ±‚/ç§’)', 'æ¯ç§’æ¥æ”¶KBæ•°', 'æ¯ç§’å‘é€KBæ•°', 'å¹³å‡å­—èŠ‚æ•°',
            # ç™»å½•ç»“æœ
            'æ³¨å†Œå‰è®¾å¤‡æ•°', 'æ³¨å†Œåè®¾å¤‡æ•°', 'å®é™…æ³¨å†Œæ•°', 'æ³¨å†ŒæˆåŠŸç‡(%)',
            # CPUç›‘æ§ï¼ˆæŒ‰é‡è¦ç¨‹åº¦æ’åºï¼‰
            'CPUå¹³å‡å€¼(%)', 'CPUæœ€å¤§å€¼(%)', 'CPU_P95(%)', 'CPU_P90(%)', 'CPUæœ€å°å€¼(%)', 'CPUå˜åŒ–ç‡(%)', 'CPUé‡‡æ ·ç‚¹æ•°',
            'CPUæ ¸å¿ƒæ•°', 'ç³»ç»Ÿè´Ÿè½½_1åˆ†é’Ÿ', 'ç³»ç»Ÿè´Ÿè½½_5åˆ†é’Ÿ', 'ç³»ç»Ÿè´Ÿè½½_15åˆ†é’Ÿ', 'CPUæ¸©åº¦(Â°C)', 'è¿›ç¨‹æ•°', 'ç³»ç»Ÿçº¿ç¨‹æ•°', 'ä¸Šä¸‹æ–‡åˆ‡æ¢æ•°',
            # å†…å­˜ç›‘æ§ï¼ˆæŒ‰é‡è¦ç¨‹åº¦æ’åºï¼‰
            'å†…å­˜å¹³å‡å€¼(%)', 'å†…å­˜æœ€å¤§å€¼(%)', 'å†…å­˜_P95(%)', 'å†…å­˜_P90(%)', 'å†…å­˜æœ€å°å€¼(%)', 'å†…å­˜å˜åŒ–ç‡(%)', 'å†…å­˜é‡‡æ ·ç‚¹æ•°',
            # ç¡¬ç›˜ç›‘æ§ï¼ˆæŒ‰é‡è¦ç¨‹åº¦æ’åºï¼‰
            'ç¡¬ç›˜å¹³å‡å€¼(%)', 'ç¡¬ç›˜æœ€å¤§å€¼(%)', 'ç¡¬ç›˜_P95(%)', 'ç¡¬ç›˜_P90(%)', 'ç¡¬ç›˜æœ€å°å€¼(%)', 'ç¡¬ç›˜å˜åŒ–ç‡(%)', 'ç¡¬ç›˜é‡‡æ ·ç‚¹æ•°',
            # æ–‡ä»¶ä¿¡æ¯
            'JTLæ–‡ä»¶', 'æŠ¥å‘Šç›®å½•', 'æµ‹è¯•æ—¶é—´'
        ]
        
        # ç”Ÿæˆæ¨ªæ ‡é¢˜æŠ¥å‘Šï¼ˆæ ‡å‡†CSVæ ¼å¼ï¼‰
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_file_horizontal = os.path.join(self.results_dir, f"batch_login_test_summary_horizontal_{timestamp}.csv")
        
        with open(csv_file_horizontal, 'w', newline='', encoding='utf-8') as f:
            # æŒ‰é‡è¦çº§åˆ«æ’åºå­—æ®µ
            ordered_fieldnames = [field for field in field_priority if field in self._get_all_fieldnames()]
            
            writer = csv.DictWriter(f, fieldnames=ordered_fieldnames)
            writer.writeheader()
            
            for result in test_results:
                row_data = self._prepare_report_row(result, ordered_fieldnames)
                writer.writerow(row_data)
        
        print(f"ğŸ“Š æ¨ªæ ‡é¢˜CSVæŠ¥å‘Šå·²ç”Ÿæˆ: {csv_file_horizontal}")
        
        # ç”Ÿæˆåˆ—æ ‡é¢˜æŠ¥å‘Šï¼ˆè½¬ç½®æ ¼å¼ï¼‰
        csv_file_vertical = os.path.join(self.results_dir, f"batch_login_test_summary_vertical_{timestamp}.csv")
        
        with open(csv_file_vertical, 'w', newline='', encoding='utf-8') as f:
            # æŒ‰é‡è¦çº§åˆ«æ’åºå­—æ®µ
            ordered_fieldnames = [field for field in field_priority if field in self._get_all_fieldnames()]
            
            writer = csv.writer(f)
            
            # å†™å…¥æ ‡é¢˜è¡Œ
            writer.writerow(['æŒ‡æ ‡åç§°'] + [result['test_name'] for result in test_results])
            
            # æŒ‰é‡è¦çº§åˆ«å†™å…¥æ¯è¡Œæ•°æ®
            for field in ordered_fieldnames:
                row_data = [field]
                for result in test_results:
                    value = self._get_field_value(result, field)
                    row_data.append(value)
                writer.writerow(row_data)
        
        print(f"ğŸ“Š åˆ—æ ‡é¢˜CSVæŠ¥å‘Šå·²ç”Ÿæˆ: {csv_file_vertical}")
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        json_file = os.path.join(self.results_dir, f"batch_login_test_summary_{timestamp}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ ç™»å½•æµ‹è¯•JSONæŠ¥å‘Šå·²ç”Ÿæˆ: {json_file}")
        
        # æ‰“å°ç™»å½•æµ‹è¯•ä¸“ç”¨æ€»ç»“
        print("\n" + "="*60)
        print(f"ğŸ¯ æ‰¹é‡ç™»å½•æµ‹è¯•æ€»ç»“ (å›ºå®šçº¿ç¨‹æ•°500)")
        print("="*60)
        
        total_expected = sum(r['expected_requests'] for r in test_results)
        total_actual = sum(r['actual_requests'] for r in test_results)
        total_success = sum(r['success_count'] for r in test_results)
        total_registered = sum(r['registered_count'] for r in test_results)
        
        # CPUç»Ÿè®¡
        all_cpu_avg = [r['cpu_avg'] for r in test_results if r['cpu_avg'] > 0]
        avg_cpu_usage = sum(all_cpu_avg) / len(all_cpu_avg) if all_cpu_avg else 0
        max_cpu_usage = max([r['cpu_max'] for r in test_results]) if test_results else 0
        
        # å†…å­˜ç»Ÿè®¡
        all_memory_avg = [r['memory_avg'] for r in test_results if r['memory_avg'] > 0]
        avg_memory_usage = sum(all_memory_avg) / len(all_memory_avg) if all_memory_avg else 0
        max_memory_usage = max([r['memory_max'] for r in test_results]) if test_results else 0
        
        # ç¡¬ç›˜ç»Ÿè®¡
        all_disk_avg = [r['disk_avg'] for r in test_results if r['disk_avg'] > 0]
        avg_disk_usage = sum(all_disk_avg) / len(all_disk_avg) if all_disk_avg else 0
        max_disk_usage = max([r['disk_max'] for r in test_results]) if test_results else 0
        
        print(f"ğŸ“Š æ€»é¢„æœŸè¯·æ±‚æ•°: {total_expected}")
        print(f"ğŸ“Š æ€»å®é™…è¯·æ±‚æ•°: {total_actual}")
        print(f"ğŸ“Š æ€»æˆåŠŸè¯·æ±‚æ•°: {total_success}")
        print(f"ğŸ“Š æ€»æ³¨å†Œè®¾å¤‡æ•°: {total_registered}")
        print(f"ğŸ“ˆ æ•´ä½“æˆåŠŸç‡: {total_success/total_actual*100:.2f}%" if total_actual > 0 else "ğŸ“ˆ æ•´ä½“æˆåŠŸç‡: 0%")
        print(f"ğŸ“ˆ æ•´ä½“æ³¨å†Œç‡: {total_registered/total_expected*100:.2f}%" if total_expected > 0 else "ğŸ“ˆ æ•´ä½“æ³¨å†Œç‡: 0%")
        print(f"ğŸ–¥ï¸  å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu_usage:.2f}%")
        print(f"ğŸ–¥ï¸  æœ€å¤§CPUä½¿ç”¨ç‡: {max_cpu_usage:.2f}%")
        print(f"ğŸ’¾ å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory_usage:.2f}%")
        print(f"ğŸ’¾ æœ€å¤§å†…å­˜ä½¿ç”¨ç‡: {max_memory_usage:.2f}%")
        print(f"ğŸ’¿ å¹³å‡ç¡¬ç›˜ä½¿ç”¨ç‡: {avg_disk_usage:.2f}%")
        print(f"ğŸ’¿ æœ€å¤§ç¡¬ç›˜ä½¿ç”¨ç‡: {max_disk_usage:.2f}%")
        
        # æŒ‰å¾ªç¯æ¬¡æ•°åˆ†æ
        print(f"\nğŸ“Š æŒ‰å¾ªç¯æ¬¡æ•°åˆ†æ:")
        for result in test_results:
            loops = result['loops']
            success_rate = result['success_rate']
            avg_response = result['avg_response_time']
            cpu_avg = result['cpu_avg']
            memory_avg = result['memory_avg']
            disk_avg = result['disk_avg']
            print(f"   {loops}å¾ªç¯: æˆåŠŸç‡={success_rate:.1f}%, å“åº”æ—¶é—´={avg_response:.1f}ms, CPU={cpu_avg:.1f}%, å†…å­˜={memory_avg:.1f}%, ç¡¬ç›˜={disk_avg:.1f}%")
        
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {self.results_dir}")
        print(f"ğŸ“„ æ¨ªæ ‡é¢˜æŠ¥å‘Š: {csv_file_horizontal}")
        print(f"ğŸ“„ åˆ—æ ‡é¢˜æŠ¥å‘Š: {csv_file_vertical}")
        print(f"ğŸ“„ JSONæŠ¥å‘Š: {json_file}")

    def _ssh_exec(self, command):
        """æ‰§è¡ŒSSHå‘½ä»¤è·å–ç¡¬ä»¶ä¿¡æ¯"""
        try:
            if hasattr(self, 'cpu_monitor') and self.cpu_monitor:
                # æ£€æŸ¥cpu_monitoræ˜¯å¦æœ‰collectorå±æ€§
                if hasattr(self.cpu_monitor, 'collector') and self.cpu_monitor.collector:
                    return self.cpu_monitor.collector._ssh_exec(command)
                # å¦‚æœæ²¡æœ‰collectorå±æ€§ï¼Œç›´æ¥å°è¯•æ‰§è¡Œ
                elif hasattr(self.cpu_monitor, '_ssh_exec'):
                    return self.cpu_monitor._ssh_exec(command)
                else:
                    print(f"âš ï¸ cpu_monitorå¯¹è±¡ç¼ºå°‘SSHæ‰§è¡Œæ–¹æ³•")
                    return "0"
            else:
                return "0"
        except Exception as e:
            print(f"âš ï¸  SSHå‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            return "0"

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆJMETERæ‰¹é‡æ³¨å†Œè„šæœ¬')
    parser.add_argument('--threads', nargs='+', type=int, default=[100, 500, 1000],
                       help='çº¿ç¨‹æ•°åˆ—è¡¨ï¼Œä¾‹å¦‚: 100 500 1000')
    parser.add_argument('--loops', nargs='+', type=int, default=[1],
                       help='å¾ªç¯æ¬¡æ•°åˆ—è¡¨ï¼Œä¾‹å¦‚: 1 5 10')
    parser.add_argument('--single', action='store_true',
                       help='å•æ¬¡æµ‹è¯•æ¨¡å¼ï¼Œåªæ‰§è¡Œä¸€ä¸ªé…ç½®')
    parser.add_argument('--test-type', choices=['register', 'login'], default='register',
                       help='æµ‹è¯•ç±»å‹: register(æ‰¹é‡æ³¨å†Œ) æˆ– login(æ‰¹é‡ç™»å½•)')
    parser.add_argument('--server-host', type=str, default='192.168.24.45',
                       help='æœåŠ¡å™¨IPåœ°å€')
    parser.add_argument('--server-user', type=str, default='test',
                       help='æœåŠ¡å™¨SSHç”¨æˆ·å')
    parser.add_argument('--server-password', type=str, default='1',
                       help='æœåŠ¡å™¨SSHå¯†ç ')
    parser.add_argument('--filter-registered', action='store_true',
                       help='æ‰§è¡Œå¢é‡æ³¨å†Œï¼Œè‡ªåŠ¨è¿‡æ»¤æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„è®¾å¤‡ã€‚')
    parser.add_argument('--iterations', type=int, default=1,
                       help='è¿­ä»£æ‰§è¡Œæ¬¡æ•°ï¼Œç”¨äºæŒç»­å‹åŠ›æµ‹è¯•ã€‚æ¯æ¬¡è¿­ä»£éƒ½ä¼šé‡æ–°è¿›è¡Œæ•°æ®è¿‡æ»¤ã€‚')
    parser.add_argument('--csv-dir', type=str, default='src/tools/jmeter/bin', help='åˆ†ç‰‡CSVæ–‡ä»¶ç›®å½•')
    parser.add_argument('--csv-pattern', type=str, default='new_devices_part_*.csv', help='åˆ†ç‰‡CSVæ–‡ä»¶é€šé…ç¬¦')
    parser.add_argument('--sharding', action='store_true', help='å¯ç”¨åˆ†ç‰‡æ‰¹é‡æ³¨å†Œæ¨¡å¼')
    parser.add_argument('--login-test', action='store_true', help='å¯ç”¨æ‰¹é‡ç™»å½•æµ‹è¯•æ¨¡å¼ï¼ˆå›ºå®šçº¿ç¨‹æ•°500ï¼Œæµ‹è¯•ä¸åŒå¾ªç¯æ¬¡æ•°ï¼‰')
    parser.add_argument('--login-loops', nargs='+', type=int, default=[1, 2, 5, 10, 20],
                       help='ç™»å½•æµ‹è¯•çš„å¾ªç¯æ¬¡æ•°åˆ—è¡¨')
    parser.add_argument('--login-range', type=str, help='ç™»å½•æµ‹è¯•å¾ªç¯æ¬¡æ•°èŒƒå›´ï¼Œæ ¼å¼ï¼šstart-endï¼Œä¾‹å¦‚ï¼š1-100')
    parser.add_argument('--login-step', type=int, default=1, help='ç™»å½•æµ‹è¯•å¾ªç¯æ¬¡æ•°æ­¥é•¿ï¼Œé»˜è®¤1')
    
    args = parser.parse_args()
    
    # æ„å»ºæµ‹è¯•é…ç½®
    if args.single:
        # å•æ¬¡æµ‹è¯•æ¨¡å¼
        thread_configs = [
            {'threads': args.threads[0], 'loops': args.loops[0]}
        ]
    else:
        # æ‰¹é‡æµ‹è¯•æ¨¡å¼
        thread_configs = []
        for thread_count in args.threads:
            for loops in args.loops:
                thread_configs.append({
                    'threads': thread_count,
                    'loops': loops
                })
    
    print("å¢å¼ºç‰ˆJMETERæ‰¹é‡æ³¨å†Œè„šæœ¬")
    print("="*60)
    print(f"ğŸ“‹ æµ‹è¯•ç±»å‹: {args.test_type}")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = EnhancedJMeterBatchRegister()
    
    # æ›´æ–°æœåŠ¡å™¨é…ç½®
    tester.server_config['host'] = args.server_host
    tester.server_config['username'] = args.server_user
    tester.server_config['password'] = args.server_password
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if args.login_test:
        # ç™»å½•æµ‹è¯•æ¨¡å¼è·³è¿‡CSVæ–‡ä»¶æ£€æŸ¥
        if not tester.check_prerequisites():
            print("âŒ å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
            return
    else:
        # å…¶ä»–æ¨¡å¼éœ€è¦æ£€æŸ¥æ‰€æœ‰å‰ç½®æ¡ä»¶
        if not tester.check_prerequisites():
            print("âŒ å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
            return
    
    try:
        if args.login_test:
            # æ‰¹é‡ç™»å½•æµ‹è¯•æ¨¡å¼
            if args.login_range:
                # è§£æèŒƒå›´å‚æ•°
                try:
                    start, end = map(int, args.login_range.split('-'))
                    step = args.login_step
                    login_loops = list(range(start, end + 1, step))
                    print(f"ğŸ“‹ ç™»å½•æµ‹è¯•å¾ªç¯æ¬¡æ•°èŒƒå›´: {start}-{end}ï¼Œæ­¥é•¿: {step}")
                    print(f"ğŸ“‹ å®é™…å¾ªç¯æ¬¡æ•°: {login_loops}")
                except ValueError:
                    print("âŒ å¾ªç¯æ¬¡æ•°èŒƒå›´æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ start-end æ ¼å¼ï¼Œä¾‹å¦‚ï¼š1-100")
                    return
            else:
                login_loops = args.login_loops
                print(f"ğŸ“‹ ç™»å½•æµ‹è¯•å¾ªç¯æ¬¡æ•°: {login_loops}")
            
            test_results = tester.run_batch_login_test(login_loops)
            print(f"\nâœ… æ‰¹é‡ç™»å½•æµ‹è¯•å®Œæˆï¼Œå…±æ‰§è¡Œ {len(test_results)} ä¸ªæµ‹è¯•")
        elif args.sharding:
            # åˆ†ç‰‡æ‰¹é‡æ³¨å†Œæ¨¡å¼
            print(f"ğŸ“‹ åˆ†ç‰‡CSVç›®å½•: {args.csv_dir}")
            print(f"ğŸ“‹ åˆ†ç‰‡CSVæ¨¡å¼: {args.csv_pattern}")
            tester.run_csv_sharding_batch_test(args.csv_dir, args.csv_pattern)
        else:
            # å¸¸è§„æ‰¹é‡æµ‹è¯•æ¨¡å¼
            print(f"ğŸ“‹ æµ‹è¯•é…ç½®æ•°é‡: {len(thread_configs)}")
            for i, config in enumerate(thread_configs):
                print(f"   é…ç½® {i+1}: {config['threads']}çº¿ç¨‹ Ã— {config['loops']}å¾ªç¯")
            
            if args.filter_registered:
                print("ğŸ” å¯ç”¨å¢é‡æ³¨å†Œæ¨¡å¼ï¼Œå°†è‡ªåŠ¨è¿‡æ»¤å·²æ³¨å†Œè®¾å¤‡")
                tester._prepare_fresh_csv()
            
            test_results = tester.run_batch_test(thread_configs, args.test_type, args.iterations)
            print(f"\nâœ… æ‰¹é‡{args.test_type}æµ‹è¯•å®Œæˆï¼Œå…±æ‰§è¡Œ {len(test_results)} ä¸ªæµ‹è¯•")
            
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        tester.stop_cpu_monitoring()
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        tester.stop_cpu_monitoring()

if __name__ == '__main__':
    main() 