#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬ä¸€é˜¶æ®µï¼šæˆ˜åœºä¾¦å¯Ÿè‡ªåŠ¨åŒ–å·¥å…·
åŠŸèƒ½ï¼šä»£ç ç»Ÿè®¡ã€æ¨¡å—å…³ç³»åˆ†æã€é‡å¤ä»£ç æ£€æµ‹ã€æ€ç»´å¯¼å›¾ç”Ÿæˆ
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple, Any
from collections import defaultdict, Counter
import re
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class CodeAnalyzer:
    """ä»£ç åˆ†æå™¨ - ç»Ÿè®¡é¡¹ç›®è§„æ¨¡å’Œå¤æ‚åº¦"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.exclude_dirs = {
            'venv', '__pycache__', '.git', 'node_modules', 
            'tools/java', 'tools/jmeter', 'tools/redis',
            'data/generated_devices', 'test_output', 'temp'
        }
        self.python_extensions = {'.py', '.pyx', '.pyi'}
        
    def count_files_and_lines(self) -> Dict[str, Any]:
        """ç»Ÿè®¡æ–‡ä»¶æ•°é‡å’Œä»£ç è¡Œæ•°"""
        stats = {
            'total_files': 0,
            'python_files': 0,
            'total_lines': 0,
            'code_lines': 0,
            'comment_lines': 0,
            'blank_lines': 0,
            'by_directory': defaultdict(lambda: {'files': 0, 'lines': 0}),
            'by_extension': Counter()
        }
        
        for root, dirs, files in os.walk(self.project_root):
            # æ’é™¤ä¸éœ€è¦åˆ†æçš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in self.exclude_dirs]
            
            for file in files:
                file_path = Path(root) / file
                rel_path = file_path.relative_to(self.project_root)
                
                # ç»Ÿè®¡æ‰€æœ‰æ–‡ä»¶
                stats['total_files'] += 1
                stats['by_extension'][file_path.suffix] += 1
                
                # ç»Ÿè®¡Pythonæ–‡ä»¶
                if file_path.suffix in self.python_extensions:
                    stats['python_files'] += 1
                    dir_name = rel_path.parts[0] if rel_path.parts else 'root'
                    stats['by_directory'][dir_name]['files'] += 1
                    
                    # åˆ†æPythonæ–‡ä»¶å†…å®¹
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            lines = f.readlines()
                            stats['total_lines'] += len(lines)
                            stats['by_directory'][dir_name]['lines'] += len(lines)
                            
                            for line in lines:
                                stripped = line.strip()
                                if not stripped:
                                    stats['blank_lines'] += 1
                                elif stripped.startswith('#'):
                                    stats['comment_lines'] += 1
                                else:
                                    stats['code_lines'] += 1
                    except Exception as e:
                        print(f"è­¦å‘Šï¼šæ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        
        return stats
    
    def analyze_module_dependencies(self) -> Dict[str, List[str]]:
        """åˆ†ææ¨¡å—ä¾èµ–å…³ç³»"""
        dependencies = defaultdict(set)
        
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if d not in self.exclude_dirs]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = Path(root) / file
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        # æå–importè¯­å¥
                        import_patterns = [
                            r'^import\s+([a-zA-Z_][a-zA-Z0-9_.]*)\s*$',
                            r'^from\s+([a-zA-Z_][a-zA-Z0-9_.]*)\s+import',
                            r'^from\s+([a-zA-Z_][a-zA-Z0-9_.]*)\s+import\s+\*'
                        ]
                        
                        for pattern in import_patterns:
                            matches = re.findall(pattern, content, re.MULTILINE)
                            for match in matches:
                                module_name = match.split('.')[0]  # å–ä¸»æ¨¡å—å
                                if module_name not in ['os', 'sys', 'json', 're', 'datetime', 'pathlib', 'typing', 'collections']:
                                    dependencies[str(file_path.relative_to(self.project_root))].add(module_name)
                                    
                    except Exception as e:
                        print(f"è­¦å‘Šï¼šæ— æ³•åˆ†ææ–‡ä»¶ {file_path}: {e}")
        
        return {k: list(v) for k, v in dependencies.items()}
    
    def detect_duplicate_code(self) -> List[Dict[str, Any]]:
        """æ£€æµ‹é‡å¤ä»£ç ç‰‡æ®µ"""
        duplicates = []
        
        # ç®€å•çš„é‡å¤ä»£ç æ£€æµ‹ï¼ˆåŸºäºå‡½æ•°å’Œç±»å®šä¹‰ï¼‰
        code_patterns = [
            (r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\([^)]*\):', 'å‡½æ•°å®šä¹‰'),
            (r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*[:\(]', 'ç±»å®šä¹‰'),
            (r'if\s+__name__\s*==\s*[\'"]__main__[\'"]:', 'ä¸»ç¨‹åºå…¥å£')
        ]
        
        pattern_counts = defaultdict(list)
        
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if d not in self.exclude_dirs]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = Path(root) / file
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        for pattern, pattern_type in code_patterns:
                            matches = re.findall(pattern, content)
                            for match in matches:
                                pattern_counts[f"{pattern_type}:{match}"].append(str(file_path.relative_to(self.project_root)))
                                    
                    except Exception as e:
                        print(f"è­¦å‘Šï¼šæ— æ³•åˆ†ææ–‡ä»¶ {file_path}: {e}")
        
        # æ‰¾å‡ºé‡å¤çš„æ¨¡å¼
        for pattern, files in pattern_counts.items():
            if len(files) > 1:
                duplicates.append({
                    'pattern': pattern,
                    'files': files,
                    'count': len(files)
                })
        
        return sorted(duplicates, key=lambda x: x['count'], reverse=True)

class MindMapGenerator:
    """æ€ç»´å¯¼å›¾ç”Ÿæˆå™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        
    def generate_mermaid_mindmap(self, dependencies: Dict[str, List[str]]) -> str:
        """ç”ŸæˆMermaidæ ¼å¼çš„æ€ç»´å¯¼å›¾"""
        mermaid_code = """graph TD
    A[é¡¹ç›®æ¶æ„] --> B[srcç›®å½•]
    A --> C[scriptsç›®å½•]
    A --> D[toolsç›®å½•]
    A --> E[docsç›®å½•]
    A --> F[å…¶ä»–æ–‡ä»¶]
    
    B --> B1[domainå±‚]
    B --> B2[applicationå±‚]
    B --> B3[infrastructureå±‚]
    B --> B4[interfaceså±‚]
    B --> B5[configå±‚]
    
    B1 --> B1A[entitieså®ä½“]
    B1 --> B1B[servicesé¢†åŸŸæœåŠ¡]
    B1 --> B1C[value_objectså€¼å¯¹è±¡]
    B1 --> B1D[strategyç­–ç•¥]
    
    B2 --> B2A[servicesåº”ç”¨æœåŠ¡]
    B2 --> B2B[jmeteræµ‹è¯•æœåŠ¡]
    B2 --> B2C[monitorç›‘æ§æœåŠ¡]
    
    B3 --> B3A[repositoriesä»“å‚¨]
    B3 --> B3B[jmeteræ‰§è¡Œå™¨]
    B3 --> B3C[reportæŠ¥å‘Šç”Ÿæˆ]
    B3 --> B3D[analysisåˆ†æå·¥å…·]
    
    B4 --> B4A[cliå‘½ä»¤è¡Œæ¥å£]
    B4 --> B4B[mainä¸»ç¨‹åº]
    
    B5 --> B5A[apié…ç½®]
    B5 --> B5B[coreæ ¸å¿ƒé…ç½®]
    B5 --> B5C[testæµ‹è¯•é…ç½®]
    
    C --> C1[Pythonè„šæœ¬]
    C --> C2[å…¶ä»–è„šæœ¬]
    
    D --> D1[jmeterå·¥å…·]
    D --> D2[rediså·¥å…·]
    D --> D3[å…¶ä»–å·¥å…·]
    
    E --> E1[apiæ–‡æ¡£]
    E --> E2[designè®¾è®¡æ–‡æ¡£]
    E --> E3[developmentå¼€å‘æ–‡æ¡£]
    E --> E4[requirementséœ€æ±‚æ–‡æ¡£]
"""
        return mermaid_code
    
    def generate_dependency_graph(self, dependencies: Dict[str, List[str]]) -> str:
        """ç”Ÿæˆä¾èµ–å…³ç³»å›¾"""
        mermaid_code = """graph LR
"""
        
        # æŒ‰ç›®å½•åˆ†ç»„
        dir_modules = defaultdict(set)
        for file_path, deps in dependencies.items():
            dir_name = file_path.split('/')[0] if '/' in file_path else 'root'
            dir_modules[dir_name].update(deps)
        
        # ç”ŸæˆèŠ‚ç‚¹
        for dir_name, modules in dir_modules.items():
            mermaid_code += f"    {dir_name.replace('-', '_')}[{dir_name}]\n"
        
        # ç”Ÿæˆè¿æ¥
        connections = set()
        for file_path, deps in dependencies.items():
            source_dir = file_path.split('/')[0] if '/' in file_path else 'root'
            for dep in deps:
                target_dir = dep.split('.')[0] if '.' in dep else dep
                if target_dir in dir_modules:
                    connection = f"{source_dir.replace('-', '_')} --> {target_dir.replace('-', '_')}"
                    if connection not in connections:
                        connections.add(connection)
                        mermaid_code += f"    {connection}\n"
        
        return mermaid_code

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def generate_html_report(self, stats: Dict[str, Any], dependencies: Dict[str, List[str]], 
                           duplicates: List[Dict[str, Any]], mindmap_code: str) -> str:
        """ç”ŸæˆHTMLæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"phase1_report_{timestamp}.html"
        
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬ä¸€é˜¶æ®µé‡æ„åˆ†ææŠ¥å‘Š</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <style>
        body {{ font-family: 'Microsoft YaHei', Arial, sans-serif; margin: 20px; }}
        .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
        .highlight {{ background-color: #f0f8ff; padding: 10px; border-radius: 3px; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .warning {{ color: #ff6b6b; }}
        .success {{ color: #51cf66; }}
    </style>
</head>
<body>
    <h1>ç¬¬ä¸€é˜¶æ®µé‡æ„åˆ†ææŠ¥å‘Š</h1>
    <p>ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
    
    <div class="section">
        <h2>ğŸ“Š é¡¹ç›®ç»Ÿè®¡æ¦‚è§ˆ</h2>
        <div class="highlight">
            <p><strong>æ€»æ–‡ä»¶æ•°ï¼š</strong>{stats['total_files']}</p>
            <p><strong>Pythonæ–‡ä»¶æ•°ï¼š</strong>{stats['python_files']}</p>
            <p><strong>æ€»ä»£ç è¡Œæ•°ï¼š</strong>{stats['total_lines']}</p>
            <p><strong>æœ‰æ•ˆä»£ç è¡Œæ•°ï¼š</strong>{stats['code_lines']}</p>
            <p><strong>æ³¨é‡Šè¡Œæ•°ï¼š</strong>{stats['comment_lines']}</p>
            <p><strong>ç©ºè¡Œæ•°ï¼š</strong>{stats['blank_lines']}</p>
        </div>
    </div>
    
    <div class="section">
        <h2>ğŸ“ æŒ‰ç›®å½•ç»Ÿè®¡</h2>
        <table>
            <tr><th>ç›®å½•</th><th>æ–‡ä»¶æ•°</th><th>ä»£ç è¡Œæ•°</th></tr>
"""
        
        for dir_name, dir_stats in sorted(stats['by_directory'].items()):
            html_content += f"            <tr><td>{dir_name}</td><td>{dir_stats['files']}</td><td>{dir_stats['lines']}</td></tr>\n"
        
        html_content += """        </table>
    </div>
    
    <div class="section">
        <h2>ğŸ”— é¡¹ç›®æ¶æ„æ€ç»´å¯¼å›¾</h2>
        <div class="mermaid">
"""
        html_content += mindmap_code
        html_content += """        </div>
    </div>
    
    <div class="section">
        <h2>âš ï¸ é‡å¤ä»£ç æ£€æµ‹</h2>
"""
        
        if duplicates:
            html_content += """        <table>
            <tr><th>é‡å¤æ¨¡å¼</th><th>å‡ºç°æ¬¡æ•°</th><th>æ–‡ä»¶åˆ—è¡¨</th></tr>
"""
            for dup in duplicates[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                files_str = ', '.join(dup['files'][:3])  # åªæ˜¾ç¤ºå‰3ä¸ªæ–‡ä»¶
                if len(dup['files']) > 3:
                    files_str += f" ... (å…±{len(dup['files'])}ä¸ªæ–‡ä»¶)"
                html_content += f"            <tr><td>{dup['pattern']}</td><td>{dup['count']}</td><td>{files_str}</td></tr>\n"
            html_content += "        </table>"
        else:
            html_content += "        <p class='success'>æœªå‘ç°æ˜æ˜¾çš„é‡å¤ä»£ç æ¨¡å¼</p>"
        
        html_content += """
    </div>
    
    <div class="section">
        <h2>ğŸ¯ é‡æ„å»ºè®®</h2>
        <ul>
            <li><strong>é«˜ä¼˜å…ˆçº§ï¼š</strong>å…³æ³¨ä»£ç è¡Œæ•°æœ€å¤šçš„ç›®å½•ï¼Œä¼˜å…ˆé‡æ„</li>
            <li><strong>ä¸­ä¼˜å…ˆçº§ï¼š</strong>å¤„ç†é‡å¤ä»£ç æ¨¡å¼ï¼Œæå–å…¬å…±é€»è¾‘</li>
            <li><strong>ä½ä¼˜å…ˆçº§ï¼š</strong>ä¼˜åŒ–æ³¨é‡Šå’Œç©ºè¡Œæ¯”ä¾‹</li>
        </ul>
    </div>
</body>
<script>
    mermaid.initialize({{ startOnLoad: true }});
</script>
</html>"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return str(report_file)
    
    def generate_markdown_report(self, stats: Dict[str, Any], dependencies: Dict[str, List[str]], 
                               duplicates: List[Dict[str, Any]]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"phase1_report_{timestamp}.md"
        
        markdown_content = f"""# ç¬¬ä¸€é˜¶æ®µé‡æ„åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´ï¼š** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š é¡¹ç›®ç»Ÿè®¡æ¦‚è§ˆ

- **æ€»æ–‡ä»¶æ•°ï¼š** {stats['total_files']}
- **Pythonæ–‡ä»¶æ•°ï¼š** {stats['python_files']}
- **æ€»ä»£ç è¡Œæ•°ï¼š** {stats['total_lines']}
- **æœ‰æ•ˆä»£ç è¡Œæ•°ï¼š** {stats['code_lines']}
- **æ³¨é‡Šè¡Œæ•°ï¼š** {stats['comment_lines']}
- **ç©ºè¡Œæ•°ï¼š** {stats['blank_lines']}

## ğŸ“ æŒ‰ç›®å½•ç»Ÿè®¡

| ç›®å½• | æ–‡ä»¶æ•° | ä»£ç è¡Œæ•° |
|------|--------|----------|
"""
        
        for dir_name, dir_stats in sorted(stats['by_directory'].items()):
            markdown_content += f"| {dir_name} | {dir_stats['files']} | {dir_stats['lines']} |\n"
        
        markdown_content += f"""
## ğŸ”— æ¨¡å—ä¾èµ–å…³ç³»

å…±å‘ç° {len(dependencies)} ä¸ªæ–‡ä»¶å­˜åœ¨æ¨¡å—ä¾èµ–å…³ç³»ã€‚

### ä¸»è¦ä¾èµ–æ¨¡å¼ï¼š
"""
        
        # ç»Ÿè®¡ä¾èµ–é¢‘ç‡
        dep_counter = Counter()
        for deps in dependencies.values():
            dep_counter.update(deps)
        
        for dep, count in dep_counter.most_common(10):
            markdown_content += f"- {dep}: è¢« {count} ä¸ªæ–‡ä»¶å¼•ç”¨\n"
        
        markdown_content += f"""
## âš ï¸ é‡å¤ä»£ç æ£€æµ‹

å‘ç° {len(duplicates)} ä¸ªé‡å¤ä»£ç æ¨¡å¼ï¼š

"""
        
        for i, dup in enumerate(duplicates[:10], 1):
            files_str = ', '.join(dup['files'][:3])
            if len(dup['files']) > 3:
                files_str += f" ... (å…±{len(dup['files'])}ä¸ªæ–‡ä»¶)"
            markdown_content += f"{i}. **{dup['pattern']}** - å‡ºç° {dup['count']} æ¬¡\n   - æ–‡ä»¶ï¼š{files_str}\n\n"
        
        markdown_content += """
## ğŸ¯ é‡æ„å»ºè®®

### é«˜ä¼˜å…ˆçº§
- å…³æ³¨ä»£ç è¡Œæ•°æœ€å¤šçš„ç›®å½•ï¼Œä¼˜å…ˆé‡æ„
- å¤„ç†é‡å¤ä»£ç æ¨¡å¼ï¼Œæå–å…¬å…±é€»è¾‘

### ä¸­ä¼˜å…ˆçº§
- ä¼˜åŒ–æ¨¡å—ä¾èµ–å…³ç³»ï¼Œå‡å°‘å¾ªç¯ä¾èµ–
- ç»Ÿä¸€ä»£ç é£æ ¼å’Œæ³¨é‡Šè§„èŒƒ

### ä½ä¼˜å…ˆçº§
- ä¼˜åŒ–æ³¨é‡Šå’Œç©ºè¡Œæ¯”ä¾‹
- å®Œå–„æ–‡æ¡£å’Œæµ‹è¯•è¦†ç›–

## ğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. æ ¹æ®ç»Ÿè®¡ç»“æœç¡®å®šé‡æ„ä¼˜å…ˆçº§
2. åˆ¶å®šè¯¦ç»†çš„æ¨¡å—è¿ç§»è®¡åˆ’
3. å¼€å§‹ç¬¬äºŒé˜¶æ®µçš„æ‰‹æœ¯è§„åˆ’
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        return str(report_file)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç¬¬ä¸€é˜¶æ®µï¼šæˆ˜åœºä¾¦å¯Ÿ")
    print("=" * 50)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = CodeAnalyzer(project_root)
    mindmap_gen = MindMapGenerator(project_root)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = project_root / "docs" / "development" / "phase1_reports"
    report_gen = ReportGenerator(output_dir)
    
    # 1. ç»Ÿè®¡ä»£ç 
    print("ğŸ“Š æ­£åœ¨ç»Ÿè®¡ä»£ç ...")
    stats = analyzer.count_files_and_lines()
    
    # 2. åˆ†æä¾èµ–å…³ç³»
    print("ğŸ”— æ­£åœ¨åˆ†ææ¨¡å—ä¾èµ–å…³ç³»...")
    dependencies = analyzer.analyze_module_dependencies()
    
    # 3. æ£€æµ‹é‡å¤ä»£ç 
    print("âš ï¸ æ­£åœ¨æ£€æµ‹é‡å¤ä»£ç ...")
    duplicates = analyzer.detect_duplicate_code()
    
    # 4. ç”Ÿæˆæ€ç»´å¯¼å›¾
    print("ğŸ—ºï¸ æ­£åœ¨ç”Ÿæˆæ€ç»´å¯¼å›¾...")
    mindmap_code = mindmap_gen.generate_mermaid_mindmap(dependencies)
    
    # 5. ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“ æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    html_report = report_gen.generate_html_report(stats, dependencies, duplicates, mindmap_code)
    md_report = report_gen.generate_markdown_report(stats, dependencies, duplicates)
    
    # 6. è¾“å‡ºç»“æœ
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“„ HTMLæŠ¥å‘Šï¼š{html_report}")
    print(f"ğŸ“„ MarkdownæŠ¥å‘Šï¼š{md_report}")
    
    # 7. è¾“å‡ºå…³é”®å‘ç°
    print("\nğŸ” å…³é”®å‘ç°ï¼š")
    print(f"- é¡¹ç›®å…±æœ‰ {stats['total_files']} ä¸ªæ–‡ä»¶ï¼Œå…¶ä¸­ {stats['python_files']} ä¸ªPythonæ–‡ä»¶")
    print(f"- æ€»ä»£ç è¡Œæ•°ï¼š{stats['total_lines']}ï¼Œæœ‰æ•ˆä»£ç è¡Œæ•°ï¼š{stats['code_lines']}")
    print(f"- å‘ç° {len(duplicates)} ä¸ªé‡å¤ä»£ç æ¨¡å¼")
    print(f"- æ¨¡å—ä¾èµ–å…³ç³»æ¶‰åŠ {len(dependencies)} ä¸ªæ–‡ä»¶")
    
    # 8. è¯†åˆ«æœ€å¤§ç›®å½•
    if stats['by_directory']:
        largest_dir = max(stats['by_directory'].items(), key=lambda x: x[1]['lines'])
        print(f"- ä»£ç é‡æœ€å¤§çš„ç›®å½•ï¼š{largest_dir[0]} ({largest_dir[1]['lines']} è¡Œ)")
    
    print("\nğŸ’¡ å»ºè®®ï¼š")
    print("1. æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šäº†è§£è¯¦ç»†åˆ†æç»“æœ")
    print("2. æ ¹æ®é‡å¤ä»£ç æ¨¡å¼åˆ¶å®šé‡æ„è®¡åˆ’")
    print("3. é‡ç‚¹å…³æ³¨ä»£ç é‡æœ€å¤§çš„ç›®å½•")
    print("4. è¿›å…¥ç¬¬äºŒé˜¶æ®µï¼šæ‰‹æœ¯è§„åˆ’")

if __name__ == "__main__":
    main()